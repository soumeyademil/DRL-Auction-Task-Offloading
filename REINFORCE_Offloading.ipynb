{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3cVEpcZR4LZ",
    "outputId": "7f58f5f1-cb13-4bfb-e1ba-20f127038231"
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# !pip3 install pandas\n",
    "# !pip3 install gymnasium[classic_control]\n",
    "# !pip3 install scikit-learn\n",
    "# !pip3 install torchvision\n",
    "# !pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udmz2pbw4583"
   },
   "outputs": [],
   "source": [
    "# Import DL and ML modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, Subset, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "## RL librairies\n",
    "# import gymnasium as gym\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "## Other librairies and modules\n",
    "import math\n",
    "from collections import OrderedDict, namedtuple, deque\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from itertools import count\n",
    "from typing import List, Optional, Tuple\n",
    "from enum import Enum\n",
    "import random\n",
    "import time\n",
    "\n",
    "## For parallelism and concurrency\n",
    "import threading\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "Transition = namedtuple('Transition',('state', 'action', 'done', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODpwrtK2HG6S",
    "outputId": "f8a8dc81-bcb2-4eb6-e02e-e5b7e3458cc1"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "logger = logging.getLogger('ddpg')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "def custom_exception_handler(exctype, value, traceback):\n",
    "    print(f\"Exception Type: {exctype}\")\n",
    "    print(f\"Exception Value: {value}\")\n",
    "    print(\"Exception Traceback:\")\n",
    "    traceback.print_tb(traceback)\n",
    "\n",
    "# Set the custom exception handler for all threads\n",
    "sys.excepthook = custom_exception_handler\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdAJSAmQRg3y",
    "outputId": "d8a6bea2-f655-455f-a46c-912c5f17a38c"
   },
   "outputs": [],
   "source": [
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47VaLHDc5PEN",
    "outputId": "c2b2661c-8469-4d0d-a534-ed6b5a542021"
   },
   "outputs": [],
   "source": [
    "# Set device to GPU or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3Blnxyx7tX7"
   },
   "outputs": [],
   "source": [
    "# Create a folder for models weights\n",
    "MODELS_PATH = 'models_weights'\n",
    "\n",
    "shutil.rmtree(MODELS_PATH, ignore_errors=True)\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-NPmO78wfN4"
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9vi4S_kZ2JX"
   },
   "outputs": [],
   "source": [
    "def generate_clients(num_clients=10):\n",
    "  # Define discrete values for each characteristic\n",
    "  cpu_cycles_values = np.random.randint(8, 12, size=num_clients) * 1e6  # Estimation of CPU cycles to process one image 28x28 with the proposed model architecture\n",
    "  frequency_values = np.random.choice([100e6, 200e6, 500e6, 1000e6], size=num_clients)  # Discrete frequency values (Hz)\n",
    "  x_coordinates = np.random.randint(0, 1001, size=num_clients)\n",
    "  y_coordinates = np.random.randint(0, 1001, size=num_clients)\n",
    "  z_coordinates = np.random.randint(0, 1001, size=num_clients)\n",
    "\n",
    "\n",
    "\n",
    "def modify_noise_model_weights(noise_model, noise_strength=0.1):\n",
    "  for param in noise_model.parameters():\n",
    "    param.data += noise_strength * torch.randn_like(param.data)\n",
    "  return noise_model\n",
    "\n",
    "\n",
    "\n",
    "def delete_models(folder_path):\n",
    "  global MODEL_POOL\n",
    "  # Verify that the provided path is a directory\n",
    "  if os.path.isdir(folder_path):\n",
    "    # Iterate over the files in the directory and delete them\n",
    "    for filename in os.listdir(folder_path):\n",
    "      # print(f'Deleting file {filename}...')\n",
    "      if int(os.path.splitext(filename)[0]) < 3/4 * len(MODEL_POOL):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "          if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "          elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "          print(f\"Error while deleting {file_path}: {e}\")\n",
    "    print(f\"Old model weights have been deleted.\")\n",
    "  else:\n",
    "    print(f\"The provided path {folder_path} is not a directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JN17vn4GijzA"
   },
   "source": [
    "### Federated Learning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3hudEppEXZI"
   },
   "outputs": [],
   "source": [
    "def load_datasets(num_clients = 10, inter_iid = True, intra_iid = True, val_ratio = 0.1, batch_size = 32, seed = 42):\n",
    "  \"\"\"Creates the dataloaders for all clients.\n",
    "  Parameters\n",
    "  ----------\n",
    "  num_clients : int\n",
    "      Number of clients in the network.\n",
    "  inter_iid : bool\n",
    "      Whether data is IID between clients.\n",
    "  intra_iid : bool\n",
    "      Whether data is IID between classes.\n",
    "  val_ratio : float\n",
    "      Ratio of validation samples.\n",
    "  batch_size : int\n",
    "      Size of a learning batch.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  trainloaders : List[Dataloader]\n",
    "      Training dataloader for all clients.\n",
    "  valloaders : List[Dataloader]\n",
    "      Validation dataloader for all clients.\n",
    "  testloader : Dataloader\n",
    "      Test dataloader to test the global model.\n",
    "  \"\"\"\n",
    "\n",
    "  datasets, testset = _partition_data(num_clients, inter_iid, intra_iid, seed)\n",
    "  # Split each partition into train/val and create DataLoader\n",
    "  trainloaders = []\n",
    "  valloaders = []\n",
    "  for dataset in datasets:\n",
    "    len_val = int(len(dataset) / (1 / val_ratio))\n",
    "    lengths = [len(dataset) - len_val, len_val]\n",
    "    ds_train, ds_val = random_split(\n",
    "        dataset, lengths, torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "    trainloaders.append(DataLoader(ds_train, batch_size=batch_size, shuffle=True))\n",
    "    valloaders.append(DataLoader(ds_val, batch_size=batch_size))\n",
    "  testloader = DataLoader(testset, batch_size=batch_size)\n",
    "  return trainloaders, valloaders, testloader\n",
    "\n",
    "\n",
    "def _download_data():\n",
    "  \"\"\"Downloads the MNIST dataset.\n",
    "  Returns\n",
    "  -------\n",
    "  trainset : Dataset\n",
    "      Dataset for training.\n",
    "  testset : Dataset\n",
    "      Dataset for testing.\n",
    "  \"\"\"\n",
    "  transform = transforms.Compose(\n",
    "      [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "  )\n",
    "  trainset = MNIST(\"./dataset\", train=True, download=True, transform=transform)\n",
    "  testset = MNIST(\"./dataset\", train=False, download=True, transform=transform)\n",
    "  return trainset, testset\n",
    "\n",
    "\n",
    "def _partition_data(num_clients=10, inter_iid=True, intra_iid=True, seed=42):\n",
    "  \"\"\"Split training set into IID or non-IID partitions to simulate different FL setting.\n",
    "  Parameters\n",
    "  ----------\n",
    "  num_clients : int\n",
    "      Number of clients in the network.\n",
    "  inter_iid : bool\n",
    "      Whether data is IID between clients.\n",
    "  intra_iid : bool\n",
    "      Whether data is IID between classes.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  datasets : List[Subset]\n",
    "      List of partioned data for all clients.\n",
    "  testset : Dataset\n",
    "      Testing dataset.\n",
    "  \"\"\"\n",
    "  trainset, testset = _download_data()\n",
    "  partition_size = int(len(trainset) / num_clients)\n",
    "  lengths = [partition_size] * num_clients\n",
    "  if inter_iid:\n",
    "      datasets = random_split(trainset, lengths, torch.Generator().manual_seed(seed))\n",
    "  else:\n",
    "      if intra_iid:\n",
    "          trainset = _balance_classes(trainset, seed)\n",
    "          partition_size = int(len(trainset) / num_clients)\n",
    "      shard_size = int(partition_size / 2)\n",
    "      idxs = trainset.targets.argsort()\n",
    "      sorted_data = Subset(trainset, idxs)\n",
    "      tmp = []\n",
    "      for idx in range(num_clients * 2):\n",
    "          tmp.append(\n",
    "              Subset(sorted_data, np.arange(shard_size * idx, shard_size * (idx + 1)))\n",
    "          )\n",
    "      idxs_list = torch.randperm(\n",
    "          num_clients * 2, generator=torch.Generator().manual_seed(seed)\n",
    "      )\n",
    "      datasets = [\n",
    "          ConcatDataset((tmp[idxs_list[2 * i]], tmp[idxs_list[2 * i + 1]]))\n",
    "          for i in range(num_clients)\n",
    "      ]\n",
    "\n",
    "  return datasets, testset\n",
    "\n",
    "\n",
    "def _balance_classes(trainset, seed=42):\n",
    "  \"\"\"Balance the classes of the trainset.\n",
    "  Parameters\n",
    "  ----------\n",
    "  trainset : Dataset\n",
    "      Training dataset.\n",
    "  seed : int\n",
    "      To initialize the random generator.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  shuffled : Subset\n",
    "      Balanced dataset.\n",
    "  \"\"\"\n",
    "  class_counts = np.bincount(trainset.targets)\n",
    "  smallest = np.min(class_counts)\n",
    "  idxs = trainset.targets.argsort()\n",
    "  tmp = [Subset(trainset, idxs[: int(smallest)])]\n",
    "  tmp_targets = [trainset.targets[idxs[: int(smallest)]]]\n",
    "  for count in class_counts:\n",
    "      tmp.append(Subset(trainset, idxs[int(count) : int(count + smallest)]))\n",
    "      tmp_targets.append(trainset.targets[idxs[int(count) : int(count + smallest)]])\n",
    "  unshuffled = ConcatDataset(tmp)\n",
    "  unshuffled_targets = torch.cat(tmp_targets)\n",
    "  shuffled_idxs = torch.randperm(\n",
    "      len(unshuffled), generator=torch.Generator().manual_seed(seed)\n",
    "  )\n",
    "  shuffled = Subset(unshuffled, shuffled_idxs)\n",
    "  shuffled.targets = unshuffled_targets[shuffled_idxs]\n",
    "\n",
    "  return shuffled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gh3ee0be5Y0x"
   },
   "outputs": [],
   "source": [
    "# Deep Network Class\n",
    "\n",
    "class Net(nn.Module):\n",
    "  \"\"\"Convolutional Neural Network architecture as described in McMahan 2017 paper :\n",
    "  [Communication-Efficient Learning of Deep Networks from\n",
    "  Decentralized Data] (https://arxiv.org/pdf/1602.05629.pdf)\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, 5, padding = 1)\n",
    "    self.conv2 = nn.Conv2d(32, 64, 5, padding = 1)\n",
    "    self.pool = nn.MaxPool2d(kernel_size = (2, 2), padding = 1)\n",
    "    self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "    self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "  def forward(self, input_tensor):\n",
    "    \"\"\"Forward pass of the CNN.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Input Tensor that will pass through the network\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The resulting Tensor after it has passed through the network\n",
    "    \"\"\"\n",
    "    output_tensor = F.relu(self.conv1(input_tensor))\n",
    "    output_tensor = self.pool(output_tensor)\n",
    "    output_tensor = F.relu(self.conv2(output_tensor))\n",
    "    output_tensor = self.pool(output_tensor)\n",
    "    output_tensor = nn.Flatten()(output_tensor)\n",
    "    output_tensor = F.relu(self.fc1(output_tensor))\n",
    "    output_tensor = self.fc2(output_tensor)\n",
    "    return output_tensor\n",
    "\n",
    "\n",
    "def train(net, trainloader, device=device, epochs=5, learning_rate=0.01, display=False):\n",
    "  \"\"\"Train the network on the training set.\n",
    "  Parameters\n",
    "  ----------\n",
    "  net : nn.Module\n",
    "      The neural network to train.\n",
    "  trainloader : DataLoader\n",
    "      The DataLoader containing the data to train the network on.\n",
    "  device : torch.device\n",
    "      The device on which the model should be trained, either 'cpu' or 'cuda'.\n",
    "  epochs : int\n",
    "      The number of epochs the model should be trained for.\n",
    "  learning_rate : float\n",
    "      The learning rate for the SGD optimizer.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  Tuple[list, list]\n",
    "      The training loss and the accuracy of the input model on the train data.\n",
    "\n",
    "  \"\"\"\n",
    "  # Performance metrics initialization\n",
    "  train_loss, train_acc = [] , []\n",
    "  # Hyperparameters\n",
    "  criterion = torch.nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "  net.train()\n",
    "\n",
    "  for i in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for images, labels in trainloader:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      # Clear the gradients\n",
    "      optimizer.zero_grad()\n",
    "      # Forward pass - compute outputs on input data using the model\n",
    "      outputs = net(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      # Backward pass\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    # Evaluate the training\n",
    "    net.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "      total_correct = 0\n",
    "      total_samples = 0\n",
    "      for images, labels in trainloader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "          outputs = net(images)\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total_samples += labels.size(0)\n",
    "          total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "      accuracy = total_correct / total_samples\n",
    "      train_acc.append(accuracy)\n",
    "      train_loss.append(loss.item())\n",
    "    net.train()\n",
    "  return train_loss, train_acc\n",
    "\n",
    "\n",
    "\n",
    "def test(net, testloader, device=device):\n",
    "  \"\"\"Evaluate the network on the entire test set.\n",
    "  Parameters\n",
    "  ----------\n",
    "  net : nn.Module\n",
    "      The neural network to test.\n",
    "  testloader : DataLoader\n",
    "      The DataLoader containing the data to test the network on.\n",
    "  device : torch.device\n",
    "      The device on which the model should be tested, either 'cpu' or 'cuda'.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  Tuple[float, float]\n",
    "      The loss and the accuracy of the input model on the given data.\n",
    "  \"\"\"\n",
    "  criterion = torch.nn.CrossEntropyLoss()\n",
    "  correct, total, loss = 0, 0, 0.0\n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "      for images, labels in testloader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          outputs = net(images)\n",
    "          loss += criterion(outputs, labels).item()\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "  if len(testloader.dataset) == 0:\n",
    "      raise ValueError(\"Testloader can't be 0, exiting...\")\n",
    "  loss /= len(testloader.dataset)\n",
    "  accuracy = correct / total\n",
    "  return loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "def get_model_size(model):\n",
    "  \"\"\"Get the neural network model weights size in bytes.\n",
    "  Parameters\n",
    "  ----------\n",
    "  model : nn.Module\n",
    "      The neural network.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  int\n",
    "      Model weights size in bytes.\n",
    "  \"\"\"\n",
    "  total_size = 0\n",
    "  for param in model.parameters():\n",
    "    total_size += np.prod(param.size())\n",
    "  return total_size * 4  # Assuming 4 bytes for each float32 value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6Olown7i2zC"
   },
   "source": [
    "### Computation, Communication and Reputation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9U94mAlFQQe"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MSG_TYPE(Enum):\n",
    "  '''Exchanged messages types\n",
    "  '''\n",
    "  OFF_REQ = 1 # Offloading request\n",
    "  BID = 2     # Auction bid\n",
    "  OFF_REP = 3 # Winner selection in the auction\n",
    "\n",
    "\n",
    "# Blockchain\n",
    "def record_to_blockchain(new_record):\n",
    "  global BC\n",
    "  global BC_LOCK\n",
    "  with BC_LOCK:\n",
    "\n",
    "    BC = pd.concat([BC, pd.DataFrame({\n",
    "            'round' : [new_record[0]],\n",
    "            'owner' : [new_record[1]],\n",
    "            'executer' : [new_record[2]],\n",
    "            'task_type' : [new_record[3]],\n",
    "            'processing_time' : [new_record[4]],\n",
    "            'communication_time' : [new_record[5]],\n",
    "            'processing_energy' : [new_record[6]],\n",
    "            'communication_energy' : [new_record[7]]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def euclidean_distance(coordinates_a, coordinates_b):\n",
    "  x1, y1, z1 = coordinates_a[0], coordinates_a[1], coordinates_a[2]\n",
    "  x2, y2, z2 = coordinates_b[0], coordinates_b[1], coordinates_b[2]\n",
    "  return np.sqrt((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2)\n",
    "\n",
    "\n",
    "# Communication model\n",
    "def channel_gain():\n",
    "  \"\"\"Calculates the channel gain between two clients\n",
    "  \"\"\"\n",
    "  # Calculate channel gain using distance-dependent path-loss model (refer to reference below)\n",
    "  # return 140.7 + 36.7 * np.log10(distance)\n",
    "  # return 1/ distance**2\n",
    "  # Uniformly distributed between [-90, -95] refer to below references (in dB)\n",
    "  return np.random.uniform(-95, -90)\n",
    "\n",
    "def transmission_rate(power, coordinates_a, coordinates_b):\n",
    "  \"\"\"Calculates the transmission rate from a sender to a receiver\n",
    "  Parameters\n",
    "  ----------\n",
    "  power: float\n",
    "      Transmission power in (mWatt).\n",
    "  h: float\n",
    "      Channel gain in (dB).\n",
    "  Returns\n",
    "  -------\n",
    "  trans_rate: float\n",
    "      Transmission rate (bits/s)\n",
    "  \"\"\"\n",
    "  global B_w         # Bandwith in (Hz)\n",
    "  global N_0         # Spectral density noise in (dBm/Hz)\n",
    "\n",
    "  # distance = euclidean_distance(coordinates_a, coordinates_b)\n",
    "  # channel_gain = np.random.uniform(1, 10, 1)[0]     # Generate the channel gain randomely\n",
    "  # channel_gain = np.random.choice([0.0001, 0.005, 0.001, 0.05, 0.01, 0.5, 0.1])\n",
    "  h = channel_gain()\n",
    "  argument = (power * 10**(h/10)) / (10**(N_0/10) * B_w)\n",
    "  trans_rate = B_w * np.log2(1 + argument)\n",
    "  return trans_rate\n",
    "\n",
    "\n",
    "def communication_time(data_size, power, coordinates_a, coordinates_b):\n",
    "  \"\"\"Calculates the communication time\n",
    "  Parameters\n",
    "  ----------\n",
    "  data_size: int\n",
    "      Size of transmitted data in bytes.\n",
    "  Returns\n",
    "  -------\n",
    "  The transmission time between a and b (Second).\n",
    "  \"\"\"\n",
    "  return data_size*8 / transmission_rate(power, coordinates_a, coordinates_b)\n",
    "\n",
    "\n",
    "def communication_energy(power, comm_time):\n",
    "  \"\"\"Calculates the communication energy.\n",
    "  Parameters\n",
    "  ----------\n",
    "  power: float\n",
    "      Transmit power in (mWatt).\n",
    "  comm_time: float\n",
    "      Communication (transmission) time in (Second).\n",
    "  Returns\n",
    "  -------\n",
    "  The transmit energy in (Joule).\n",
    "  \"\"\"\n",
    "  return power * comm_time / 1000  # Divide by 1000 to convert to Joule\n",
    "\n",
    "\n",
    "# Computation model\n",
    "def training_time(data_size, cpu_cycles, cpu_frequency, epochs):\n",
    "  \"\"\"Calculates the time spent by a client to perform a training task.\n",
    "  Parameters\n",
    "  ----------\n",
    "  data_size: int\n",
    "      Trained data size in (Bytes).\n",
    "  cpu_cycles: float\n",
    "      Number of CPU cycles to process one unit of data (image of 28*28 Bytes).\n",
    "  cpu_frequency: float\n",
    "      CPU frequency in (Hz).\n",
    "  epochs: int\n",
    "      Number of local training epochs.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  Local training time (Second).\n",
    "  \"\"\"\n",
    "  return data_size * cpu_cycles * epochs / cpu_frequency\n",
    "\n",
    "\n",
    "def validation_time(data_size, cpu_cycles, cpu_frequency):\n",
    "  \"\"\"Calculates the time spent by a client to perform a validation task.\n",
    "  Parameters\n",
    "  ----------\n",
    "  data_size: int\n",
    "      Size of used dataset for validation.\n",
    "  cpu_cycles: int\n",
    "      Number of CPU cycles required to process one unit of data (image of 28*28 Bytes).\n",
    "  cpu_frequency: float\n",
    "      CPU frequency in (Hz).\n",
    "  Returns\n",
    "  -------\n",
    "  Validation time (Second).\n",
    "  \"\"\"\n",
    "  return data_size * cpu_cycles / cpu_frequency\n",
    "\n",
    "\n",
    "def aggregation_time(M, weights_size, cpu_cycles, cpu_frequency):\n",
    "  \"\"\"Calculates the time spent by a client to perform an aggeragtion task.\n",
    "  Parameters\n",
    "  ----------\n",
    "  M: int\n",
    "      Number of aggregated models.\n",
    "  weights_size: int\n",
    "      Size of model weights in (Bytes).\n",
    "  cpu_frequency: float\n",
    "      CPU frequency in (Hz).\n",
    "  Returns\n",
    "  -------\n",
    "  Aggregation time.\n",
    "  \"\"\"\n",
    "\n",
    "  # For simplification, we consider the cpu_cycles required are proportional to cpu_cycles attribute (dedicated for training tasks)\n",
    "  cycles = cpu_cycles // 1e5\n",
    "  return (M - 1) * weights_size * cycles / cpu_frequency\n",
    "\n",
    "\n",
    "def computation_energy(capacitance, frequency, cpt_time):\n",
    "  \"\"\"Calculates the energy consumed to perform a computation task.\n",
    "  Parameters\n",
    "  ----------\n",
    "  capacitance: float\n",
    "      Client capacitance factor.\n",
    "  frequency: float\n",
    "      CPU frequency in (Hz)\n",
    "  cpt_time: float\n",
    "      Processing time in (Second)\n",
    "  Returns\n",
    "  -------\n",
    "  The processing energy (Joule).\n",
    "  \"\"\"\n",
    "  return capacitance * frequency**3 * cpt_time\n",
    "\n",
    "\n",
    "\n",
    "# Reputation model\n",
    "def update_data_quality(w_old, w_new, w_i, mu_old, lambd=0.25):\n",
    "  ''' Updates the client's data quality\n",
    "  Parameters\n",
    "  ----------\n",
    "  w_old: OrderedDict\n",
    "      Old global model weigths (previous round).\n",
    "  w_new: OrderedDict\n",
    "      New global model weigths (current round).\n",
    "  w_i: OrderedDict\n",
    "      Local model weights (current round).\n",
    "  mu_old: float\n",
    "      Old value of data quality.\n",
    "  lambd: float\n",
    "      Quality data score discount factor.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  mu_new: float\n",
    "      New data quality score.\n",
    "\n",
    "  '''\n",
    "  # flat_w_old = torch.cat([p.view(-1) for p in w_old.values()])\n",
    "  flat_w_new = torch.cat([p.view(-1) for p in w_new.values()])\n",
    "  flat_w_i = torch.cat([p.view(-1) for p in w_i.values()])\n",
    "\n",
    "  # numerator = torch.norm(flat_w_old - flat_w_i, p=2)\n",
    "  # denominator = torch.norm(flat_w_old - flat_w_new, p=2)\n",
    "  distance = torch.norm(flat_w_new - flat_w_i, p=2)\n",
    "\n",
    "  # mu_new = (1 - lambd) * (numerator / denominator) + (lambd * mu_old)\n",
    "  mu_new = (1 - lambd) / distance + (lambd * mu_old)\n",
    "  return float(mu_new)\n",
    "\n",
    "\n",
    "def update_resource_contribution(task_dict_list, eta_old, lambd=0.25, scaling_factor=1e4):\n",
    "  ''' Updates the client's resource contribution.\n",
    "  Parameters\n",
    "  ----------\n",
    "  task_dict_list: List[Dict]\n",
    "      List of tasks performed by a given client.\n",
    "  eta_old: float\n",
    "      Old value of resource contribution.\n",
    "  lambd: float\n",
    "      Resource contribution score discount factor.\n",
    "  scaling_factor: float\n",
    "      Factor to rescale the numerator of performance index.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  eta_new: float\n",
    "      New value of resource contribution.\n",
    "  '''\n",
    "  c_i = 0\n",
    "  overhead = 0\n",
    "  if not task_dict_list == None:\n",
    "    for task_dict in task_dict_list:\n",
    "      c_i += task_dict['task_count'] * scaling_factor / (task_dict['processing_time'] * task_dict['processing_energy'] + task_dict['communication_time'] * task_dict['communication_energy'])\n",
    "    eta_new = (1 - lambd) * c_i + lambd * eta_old\n",
    "  else:\n",
    "    eta_new = lambd * eta_old\n",
    "    c_i = 1e-10\n",
    "  return eta_new, c_i\n",
    "\n",
    "\n",
    "def update_offload_history(old_phi, lambd=0.9):\n",
    "  ''' Updates the client's offload history score\n",
    "  Parameters\n",
    "  ----------\n",
    "  old_phi: float\n",
    "      Old value of offloading history score.\n",
    "  lambd: float\n",
    "      Offload history score discount factor.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  new_phi: float\n",
    "      New offload history score.\n",
    "\n",
    "  '''\n",
    "  # new_phi = 1 + lambd * old_phi\n",
    "  new_phi = lambd * old_phi + 1e-10\n",
    "  return new_phi\n",
    "\n",
    "\n",
    "def update_validation_score(new_nu, old_nu, lambd=0.25):\n",
    "  return (1-lambd) * new_nu + lambd * old_nu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_reputation_score(mu, eta, phi, nu, a_1=0.27, a_2=0.27, a_3=0.2, a_4=0.26):\n",
    "  ''' Calculates reputation score given components of reputation vector.\n",
    "  Parameters\n",
    "  ----------\n",
    "  mu: float\n",
    "      Data quality score.\n",
    "  eta: float\n",
    "      Resource contribution score.\n",
    "  phi: float\n",
    "      Offloading history score.\n",
    "  nu: float\n",
    "      Validation score.\n",
    "  a_1, a_2, a_3, a_4: float\n",
    "      Weighting factors.\n",
    "  Returns\n",
    "  -------\n",
    "  Reputation score.\n",
    "\n",
    "  '''\n",
    "  sub_scores = [a_1 * mu, a_2 * eta, a_3 * phi, a_4 * nu]\n",
    "  return float(sum(sub_scores)), sub_scores\n",
    "\n",
    "# def update_gratefulness()\n",
    "\n",
    "\n",
    "\n",
    "def read_reputation(client_id, as_dict=False):\n",
    "  ''' Extracts reputation vector corresponsing to one client.\n",
    "  Parameters\n",
    "  ----------\n",
    "  client_id: int\n",
    "      Client ID.\n",
    "  as_dict: bool\n",
    "      Whether reputation vector is returned as a dict or a list.\n",
    "\n",
    "  Returns\n",
    "  ------\n",
    "  reputation vector: List/ Dict\n",
    "      Client's reputation vector.\n",
    "  '''\n",
    "  global REPUTATION_DATA\n",
    "  global CURRENT_ROUND\n",
    "  if as_dict:\n",
    "    reputation_vector = REPUTATION_DATA.loc[(REPUTATION_DATA['round'] == CURRENT_ROUND - 1) & (REPUTATION_DATA['client_id'] == client_id)].to_dict(orient='records')[0]\n",
    "  else:\n",
    "    reputation_vector = REPUTATION_DATA.loc[(REPUTATION_DATA['round'] == CURRENT_ROUND - 1) & (REPUTATION_DATA['client_id'] == client_id)][['data_quality_norm', 'resource_contribution_norm', 'offloading_history', 'validation_score_norm']].values[0]\n",
    "  return reputation_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR9iBwBrje7v"
   },
   "source": [
    "### Client Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVskeLK6EGJc"
   },
   "outputs": [],
   "source": [
    "# Client class\n",
    "class Client(threading.Thread):\n",
    "  '''Federated learning client\n",
    "  '''\n",
    "\n",
    "  def __init__(self, id, coordinates, trainloader, valloader, epochs, learning_rate, capacitance, cpu_cycles, power, frequency):\n",
    "    self.id = id\n",
    "    self.wallet = 0\n",
    "    # Coordinates\n",
    "    self.coordinates = coordinates\n",
    "    # DL attributes\n",
    "    self.net = Net().to(device=device)\n",
    "    self.trainloader = trainloader\n",
    "    self.valloader = valloader\n",
    "    self.epochs = epochs\n",
    "    self.learning_rate = learning_rate\n",
    "    # Hardware specifications\n",
    "    self.capacitance = capacitance\n",
    "    self.cpu_cycles = cpu_cycles\n",
    "    self.power = power\n",
    "    self.frequency = frequency\n",
    "    # DDPG agent\n",
    "    global DRL_DISCOUNT_FACTOR, DRL_TAU, hidden_size, n_observations, env\n",
    "    self.ddpg_agent = DDPG(\n",
    "              DRL_DISCOUNT_FACTOR,\n",
    "              DRL_TAU,\n",
    "              hidden_size,\n",
    "              n_observations,\n",
    "              env.action_space,\n",
    "              checkpoint_dir='./saved_models/BiddingEnv-v0'\n",
    "              )\n",
    "    self.replay_memory = ReplayMemory()\n",
    "    self.ddpg_step = 0\n",
    "    # Reset entity's flags\n",
    "    self.reset()\n",
    "\n",
    "\n",
    "  def reset(self):\n",
    "    '''\n",
    "    Reset flags at the begining of each round\n",
    "    Parameters\n",
    "    ----------\n",
    "    -\n",
    "    Returns\n",
    "    -------\n",
    "    -\n",
    "    '''\n",
    "    # Training metrics\n",
    "    self.train_acc = [0]\n",
    "    self.train_loss = [0]\n",
    "\n",
    "    self.val_acc = 0\n",
    "    self.val_loss = 0\n",
    "    # State flags\n",
    "    self.is_available = True                    # Flag for availability : A node can be active but not available for a given task\n",
    "    self.is_active = True\n",
    "    self.completed_train = False                # Flag for tracking local training task\n",
    "    self.offload = False\n",
    "    # Mutex variables\n",
    "    self.notification_mutex = threading.Lock()  # To protect notification\n",
    "    self.buffer_mutex = threading.Lock()        # To lock client's buffer\n",
    "    # Critical resources\n",
    "    self.notification = threading.Event()       # To receive notifications\n",
    "    self.buffer = []                            # Client's buffer\n",
    "    # DDPG flag\n",
    "    self.start_ddpg = None\n",
    "    self.finish_ddpg = None\n",
    "\n",
    "\n",
    "\n",
    "  def run(self):\n",
    "    '''\n",
    "    Run client thread\n",
    "    Parameters\n",
    "    ----------\n",
    "    -\n",
    "    Returns\n",
    "    -------\n",
    "    -\n",
    "    '''\n",
    "    global END_ROUND_LOCK                             # Protect END_ROUND flag\n",
    "    global END_ROUND                                  # END_ROUND flag\n",
    "    global END_TASK                                   # END_TASK flag\n",
    "    global selected_clients\n",
    "    global MODEL_POOL_LOCK\n",
    "    global MODEL_POOL\n",
    "    global NUM_CLIENTS\n",
    "    global MODELS_PATH\n",
    "    global DRL_BATCH_SIZE\n",
    "\n",
    "    eliminated = False\n",
    "    while not END_TASK and not eliminated:\n",
    "      time.sleep(1)\n",
    "      while not END_ROUND and self.is_active:         # Do during a communication round\n",
    "        if self not in selected_clients:\n",
    "          eliminated = True\n",
    "        if eliminated:\n",
    "          break\n",
    "        if CURRENT_ROUND > 1:\n",
    "          self.update_ddpg()\n",
    "          self.aggregate_ddpg()\n",
    "        self.reset()                                  # Reset local flags\n",
    "        # Retrieve global model (the one with max level values from the last round)\n",
    "        model_id = MODEL_POOL[MODEL_POOL['round'] == CURRENT_ROUND-1]['level'].idxmax()\n",
    "\n",
    "        self.net.load_state_dict(torch.load(f'{MODELS_PATH}/{model_id}.pth'))\n",
    "        self.fit()                                    # Perform local training task (main task)\n",
    "        time.sleep(2)\n",
    "        i = 0\n",
    "        while self.is_available:                      # Client is available for new tasks\n",
    "          # Check for offloading requests\n",
    "          with self.buffer_mutex:\n",
    "            if len(self.buffer) != 0:                 # Read message if any\n",
    "              self.is_available = False\n",
    "              self.process_message(self.buffer.pop(0))     # Process received message\n",
    "              # self.buffer = []\n",
    "          # Check newly submitted models\n",
    "          # For validation\n",
    "          with MODEL_POOL_LOCK:\n",
    "            round_condition = MODEL_POOL['round'] == CURRENT_ROUND\n",
    "            id_condition    = (MODEL_POOL['trainer'] != self.id) & (MODEL_POOL['owner'] != self.id)\n",
    "            lock_condition  = MODEL_POOL['lock'] == False\n",
    "            # Check if local model (for simplicity only local models are validated) and not validated yet\n",
    "            validated_condition = (MODEL_POOL['validators'].apply(lambda x: len(x) < 3)) & (MODEL_POOL['aggregators'].apply(lambda x: len(x) == 0))\n",
    "            validator_condition = MODEL_POOL['validators'].apply(lambda x: not self.id in x)\n",
    "            result_df = MODEL_POOL[round_condition & id_condition & lock_condition & validated_condition & validator_condition]\n",
    "            if not result_df.empty:\n",
    "              model_id = int(result_df.index[0])\n",
    "              MODEL_POOL.at[model_id, 'lock'] = True\n",
    "            # time.sleep(5)\n",
    "          # Load model's weights\n",
    "          if not result_df.empty:\n",
    "            time.sleep(random.uniform(5, 20))\n",
    "            weights = torch.load(f'{MODELS_PATH}/{model_id}.pth')\n",
    "            # Evaluate model\n",
    "            self.is_available = False\n",
    "            owner_id = int(MODEL_POOL.at[model_id, 'owner'])\n",
    "            validation_score = self.evaluate(owner_id, weights)\n",
    "            print(f'  Client {self.id:>{3}}: Model {model_id:>{5}} validated')\n",
    "            with MODEL_POOL_LOCK:\n",
    "              MODEL_POOL.at[model_id, 'lock'] = False\n",
    "              MODEL_POOL.at[model_id, 'validation_score'] = MODEL_POOL.at[model_id, 'validation_score'] + 1/3 * validation_score\n",
    "              MODEL_POOL.at[model_id, 'validators'].append(self.id)\n",
    "              # print(f'  Client {self.id}: Releasing MODEL_POOL_LOCK..')\n",
    "\n",
    "          # For aggregation\n",
    "          with MODEL_POOL_LOCK:\n",
    "            round_condition = (MODEL_POOL['round'] == CURRENT_ROUND)\n",
    "            lock_condition = (MODEL_POOL['lock'] == False)\n",
    "            # validated_condition = (MODEL_POOL['validation_score'] == 3) | (MODEL_POOL['level'] > 1)\n",
    "            validated_condition = (MODEL_POOL['level'] > 1) | (MODEL_POOL['validators'].apply(lambda x: len(x) == 3))\n",
    "            aggregated_condition = (MODEL_POOL['aggregated'] == False)\n",
    "            level_condition = MODEL_POOL['level'] < NUM_CLIENTS\n",
    "            # Check if local model (for simplicity only local models are validated) and not validated yet\n",
    "            result_df = MODEL_POOL[round_condition & lock_condition & validated_condition & aggregated_condition & level_condition]\n",
    "            if not result_df.empty and len(result_df) > 1:\n",
    "              idx = result_df.index.to_list()\n",
    "              for model_id in idx:\n",
    "                MODEL_POOL.at[model_id, 'lock'] = True\n",
    "              time.sleep(5)\n",
    "          if not result_df.empty and len(result_df) > 1:\n",
    "            self.is_available = False\n",
    "            self.aggregate(idx)\n",
    "\n",
    "          # Set is_available flag to True again\n",
    "          self.is_available = True\n",
    "\n",
    "          if not END_ROUND:                             # If everyone has completed their learning tasks\n",
    "            if all([client.completed_train for client in selected_clients]):\n",
    "              if len(MODEL_POOL[(MODEL_POOL['round'] == CURRENT_ROUND) & (MODEL_POOL['aggregated'] == False)]) == 1:\n",
    "                # Set END ROUND\n",
    "                with END_ROUND_LOCK:\n",
    "                  if not END_ROUND:\n",
    "                    # Rescale global model if any missing local models\n",
    "                    round_models = MODEL_POOL[MODEL_POOL['round'] == CURRENT_ROUND]\n",
    "                    missing_clients = len(set(selected_clients) - set(round_models['owner']))\n",
    "                    global_model_id = MODEL_POOL[(MODEL_POOL['round'] == CURRENT_ROUND) & (MODEL_POOL['aggregated'] == False)].index[0]\n",
    "                    weights = torch.load(f'{MODELS_PATH}/{global_model_id}.pth')\n",
    "                    weights = self.scale_model_weights(weights, len(selected_clients)/missing_clients)\n",
    "                    torch.save(weights, f'{MODELS_PATH}/{global_model_id}.pth')\n",
    "                    time.sleep(2)\n",
    "                    # Set flag\n",
    "                    print(f'  Client {self.id:>{3}}: Setting END_ROUND flag')\n",
    "                    END_ROUND = True\n",
    "          if END_ROUND:\n",
    "            break\n",
    "        if END_ROUND:\n",
    "          break\n",
    "      if END_ROUND:\n",
    "        break\n",
    "    if eliminated:\n",
    "      print(f'    Client {self.id}: Client eliminated...')\n",
    "\n",
    "\n",
    "\n",
    "  def update_ddpg(self):\n",
    "    global env, CURRENT_ROUND, BID_POOL, ENV_LOCK\n",
    "    global STEPS_PER_EP, METRICS_LOCK, ACTOR_LOSS, CRITIC_LOSS\n",
    "\n",
    "    condition = (BID_POOL['round'] == CURRENT_ROUND-1) & (BID_POOL['agent_id'] == self.id)\n",
    "    bids = BID_POOL.loc[condition]\n",
    "    i = -1\n",
    "    if not bids.empty:\n",
    "      for index, r in bids.iterrows():\n",
    "        i += 1\n",
    "        row = r.to_dict()\n",
    "        self.ddpg_step = self.ddpg_step % STEPS_PER_EP\n",
    "        # if first record and step != 0\n",
    "        if (i == 0) and (self.ddpg_step != 0) and (CURRENT_ROUND > 2):\n",
    "          prev_round = CURRENT_ROUND - 2\n",
    "          while (BID_POOL.loc[(BID_POOL['round'] == prev_round) & (BID_POOL['agent_id'] == self.id)].empty) and (prev_round >= 1):\n",
    "            prev_round -= 1\n",
    "          if not BID_POOL.loc[(BID_POOL['round'] == prev_round) & (BID_POOL['agent_id'] == self.id)].empty:\n",
    "            prev_bids = BID_POOL.loc[(BID_POOL['round'] == prev_round) & (BID_POOL['agent_id'] == self.id)]\n",
    "            prev_obs = prev_bids.iloc[len(prev_bids)-1].to_dict()\n",
    "            with ENV_LOCK:\n",
    "              env.set_obs(prev_obs['agent_id'], prev_obs['composed_reputation'], prev_obs['composed_reputation'], prev_obs['c_idx'], prev_obs['payment'])\n",
    "              observation = env.get_obs(prev_obs['agent_id'])\n",
    "            observation = torch.Tensor(observation).to(device)\n",
    "            _, reward, _, info = env.step_(prev_obs['agent_id'], prev_obs['winner'], prev_obs['composed_reputation'], prev_obs['composed_reputation'], prev_obs['c_idx'], prev_obs['bid'], prev_obs['fair_payment'])\n",
    "            reward = torch.Tensor([reward]).to(device)\n",
    "            action = prev_obs['bid']\n",
    "            action = torch.Tensor([float(action)]).to(device)\n",
    "            done = True if self.ddpg_step == STEPS_PER_EP - 1 else False\n",
    "            mask = torch.Tensor([done]).to(device)\n",
    "            with ENV_LOCK:\n",
    "              env.set_obs(row['agent_id'], row['composed_reputation'], row['composed_reputation'], row['c_idx'], row['payment'])\n",
    "              next_observation = env.get_obs(row['agent_id'])\n",
    "            next_observation = torch.Tensor(next_observation).to(device)\n",
    "            self.replay_memory.push(observation, action, mask, next_observation, reward)\n",
    "            self.ddpg_step += 1\n",
    "            self.ddpg_step = self.ddpg_step % STEPS_PER_EP\n",
    "\n",
    "        # register current row to replay memory\n",
    "        with ENV_LOCK:\n",
    "          env.set_obs(row['agent_id'], row['composed_reputation'], row['composed_reputation'], row['c_idx'], row['payment'])\n",
    "          observation = env.get_obs(row['agent_id'])\n",
    "        observation = torch.Tensor(observation).to(device)\n",
    "        # print(f' Client {self.id:>{3}}: {row[\"winner\"]} {row[\"c_idx\"]} {row[\"bid\"]} {row[\"fair_payment\"]}')\n",
    "        _, reward, _, info = env.step_(row['agent_id'], row['winner'], row['composed_reputation'], row['composed_reputation'], row['c_idx'], row['bid'], row['fair_payment'])\n",
    "        reward = torch.Tensor([reward]).to(device)\n",
    "        action = row['bid']\n",
    "        action = torch.Tensor([float(action)]).to(device)\n",
    "\n",
    "        if self.ddpg_step == STEPS_PER_EP - 1:\n",
    "          next_observation = observation\n",
    "          done = True\n",
    "          mask = torch.Tensor([done]).to(device)\n",
    "          next_observation = torch.Tensor(next_observation).to(device)\n",
    "          self.replay_memory.push(observation, action, mask, next_observation, reward)\n",
    "          self.ddpg_step += 1\n",
    "          self.ddpg_step = self.ddpg_step % STEPS_PER_EP\n",
    "        elif (i < len(bids) - 1):\n",
    "          next_row = bids.iloc[i + 1].to_dict()\n",
    "          with ENV_LOCK:\n",
    "            env.set_obs(next_row['agent_id'], next_row['composed_reputation'], next_row['composed_reputation'], next_row['c_idx'], next_row['payment'])\n",
    "            next_observation = env.get_obs(row['agent_id'])\n",
    "          done = False\n",
    "          mask = torch.Tensor([done]).to(device)\n",
    "          next_observation = torch.Tensor(next_observation).to(device)\n",
    "          self.replay_memory.push(observation, action, mask, next_observation, reward)\n",
    "          self.ddpg_step += 1\n",
    "          self.ddpg_step = self.ddpg_step % STEPS_PER_EP\n",
    "        else:\n",
    "          pass\n",
    "    # print(f'  Client {self.id:>{3}}: Replay Memory : {self.replay_memory.memory}...')\n",
    "    if len(self.replay_memory) > STEPS_PER_EP:\n",
    "      self.start_ddpg = True\n",
    "      transitions = self.replay_memory.get_last_episode(STEPS_PER_EP)\n",
    "      batch = Transition(*zip(*transitions))\n",
    "      print(f'Client {self.id} Batch: {batch}')\n",
    "      p_loss = self.ddpg_agent.update_params(batch, agent_id=self.id)\n",
    "      with METRICS_LOCK:\n",
    "        ACTOR_LOSS[CURRENT_ROUND-1].append(p_loss)\n",
    "      self.finish_ddpg = True\n",
    "    else:\n",
    "      self.start_ddpg = False\n",
    "\n",
    "\n",
    "  def aggregate_ddpg(self):\n",
    "    global selected_clients, AGENT_LOCK, DDPG_AGENT, DDPG_AGGREGATED, DDPG_CHECK\n",
    "    time.sleep(random.uniform(1, 5))\n",
    "    with AGENT_LOCK:\n",
    "      if DDPG_CHECK == False:\n",
    "        DDPG_CHECK = True\n",
    "        while any([client.start_ddpg is None for client in selected_clients]):\n",
    "          time.sleep(1)\n",
    "        while any([(client.start_ddpg) and (not client.finish_ddpg) for client in selected_clients]):\n",
    "          time.sleep(1)\n",
    "\n",
    "        trained_agents = [client.ddpg_agent for client in selected_clients if (client.start_ddpg and client.finish_ddpg)]\n",
    "        if(len(trained_agents) > 1):\n",
    "          num_agents = len(trained_agents)\n",
    "\n",
    "          policy_network_list = [self.scale_model_weights(agent.policy_network.state_dict(), 1/num_agents) for agent in trained_agents]\n",
    "          # Aggregate scaled\n",
    "          global_policy = self.fedavg(policy_network_list)\n",
    "\n",
    "          DDPG_AGENT.policy_network.load_state_dict(copy.deepcopy(global_policy), strict=True)\n",
    "\n",
    "          DDPG_AGGREGATED = True\n",
    "          time.sleep(2)\n",
    "\n",
    "      if DDPG_AGGREGATED == True:\n",
    "        self.ddpg_agent.policy_network.load_state_dict(copy.deepcopy(DDPG_AGENT.policy_network.state_dict()), strict=True)\n",
    "\n",
    "\n",
    "\n",
    "  def process_message(self, message):\n",
    "    '''\n",
    "    Process messages from client's buffer\n",
    "    Parameters\n",
    "    ----------\n",
    "    message : dict[MSG_TYPE, dict]\n",
    "        Message to process.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    -\n",
    "    '''\n",
    "    # Set client momentarily not available\n",
    "    self.is_available = False\n",
    "    global AUCTION_BID_KEYS\n",
    "    global CURRENT_ROUND\n",
    "    global selected_clients\n",
    "    global env, REPLAY_MEMORY, AGENT_LOCK\n",
    "    global MEAN_REWARD, METRICS_LOCK\n",
    "    global BID_POOL, BID_POOL_LOCK\n",
    "\n",
    "    if 'message_type' in message and  'message_body' in message:    # Check if message structure is correct\n",
    "\n",
    "      ### If offloading request\n",
    "      if message['message_type'] == MSG_TYPE.OFF_REQ:\n",
    "        # Extract message information\n",
    "        auction_ID = message['message_body']['auction_ID']\n",
    "        auctioneer_ID = message['message_body']['auctioneer_ID']\n",
    "        offer = message['message_body']['offer']\n",
    "        print(f'  Client {self.id:>{3}}: received message OFF_REQ from client {auctioneer_ID:>{3}}...')\n",
    "        # Send bid to the auctioneer\n",
    "        auc_reputation = read_reputation(auctioneer_ID)\n",
    "        own_reputation = read_reputation(self.id)\n",
    "        composed_reputation = [auc_reputation[0], own_reputation[1], auc_reputation[2], own_reputation[3]]\n",
    "\n",
    "        for client in selected_clients:\n",
    "          if client.id == auctioneer_ID:\n",
    "            break\n",
    "\n",
    "        remaining_epochs = offer['task_info']['remaining_epochs']\n",
    "        processing_time = training_time(client.get_data_size() * 100, self.cpu_cycles, self.frequency, remaining_epochs)\n",
    "        processing_energy = computation_energy(self.capacitance, self.frequency, processing_time)\n",
    "        comm_time       = communication_time(client.get_data_size() * DATA_UNIT_SIZE + MODEL_WEIGHTS_SIZE, self.power, self.coordinates, client.coordinates)\n",
    "        comm_energy = communication_energy(self.power, comm_time)\n",
    "        task_summary = [{\n",
    "            'task_count' : 1,\n",
    "            'processing_time' : processing_time,\n",
    "            'communication_time' : comm_time,\n",
    "            'processing_energy' : processing_energy,\n",
    "            'communication_energy' : comm_energy\n",
    "          }]\n",
    "        _, c_idx = update_resource_contribution(task_summary, 0)\n",
    "        # print(f'    Estimated performance: {c_idx}...')\n",
    "\n",
    "        with ENV_LOCK:\n",
    "          env.set_obs(self.id,\n",
    "                    own_reputation,\n",
    "                    auc_reputation,\n",
    "                    c_idx,\n",
    "                    offer['sharing_portion']\n",
    "                  )\n",
    "\n",
    "        time.sleep(2)\n",
    "        # Place a bid\n",
    "        # print(f'Set observation is {env.get_obs(self.id)}')\n",
    "        bid, true_action = self.place_bid(offer)\n",
    "\n",
    "\n",
    "        # Save observation in bid pool to avoid overwriting it by next auction information\n",
    "        with BID_POOL_LOCK:\n",
    "\n",
    "          BID_POOL = pd.concat([BID_POOL, pd.DataFrame({\n",
    "              'round' : [CURRENT_ROUND],\n",
    "              'agent_id' : [self.id],\n",
    "              'auctioneer_id' : [auctioneer_ID],\n",
    "              'composed_reputation' : [[auc_reputation[0], own_reputation[1], auc_reputation[2], own_reputation[3]]],\n",
    "              'bid': [bid],\n",
    "              'c_idx' : [c_idx],\n",
    "              'payment': [offer['sharing_portion']]\n",
    "          })], ignore_index=True)\n",
    "\n",
    "\n",
    "        # Compose bid message\n",
    "        auction_bid_values = [time.time(), auction_ID, self.id, bid, true_action]\n",
    "        bid_message_body = {key: value for key, value in zip(AUCTION_BID_KEYS, auction_bid_values)}\n",
    "\n",
    "        print(f'  Client {self.id:>{3}}: Placing bid {bid} to client {auctioneer_ID:>{3}}')\n",
    "        self.send_message(client, MSG_TYPE.BID, bid_message_body)\n",
    "\n",
    "      ### If offloading response\n",
    "      elif message['message_type'] == MSG_TYPE.OFF_REP:\n",
    "        # Message body structure: ['timestamp', 'auction_ID', 'round', 'auctioneer_id', 'composed_reputation', 'bid', 'payment', 'task_args']\n",
    "        for auctioneer in selected_clients:\n",
    "            if auctioneer.id == message['message_body']['auctioneer_id']:\n",
    "              break\n",
    "        # If task_args != None then this is the auction winner\n",
    "        winner = (message['message_body']['task_args'] != None)\n",
    "        if winner:\n",
    "          # If auction winner, calculate costs\n",
    "          processing_time = training_time(auctioneer.get_data_size() * 100, self.cpu_cycles, self.frequency, message['message_body']['task_args'][1])\n",
    "          processing_energy = computation_energy(self.capacitance, self.frequency, processing_time)\n",
    "          comm_time       = communication_time(auctioneer.get_data_size() * DATA_UNIT_SIZE + MODEL_WEIGHTS_SIZE, self.power, self.coordinates, auctioneer.coordinates)\n",
    "          comm_energy = communication_energy(self.power, comm_time)\n",
    "          task_summary = [{\n",
    "              'task_count' : 1,\n",
    "              'processing_time' : processing_time,\n",
    "              'communication_time' : comm_time,\n",
    "              'processing_energy' : processing_energy,\n",
    "              'communication_energy' : comm_energy\n",
    "            }]\n",
    "          _, c_idx = update_resource_contribution(task_summary, 0)\n",
    "        else:\n",
    "          c_idx = 0.\n",
    "\n",
    "        auc_reputation = read_reputation(message['message_body']['auctioneer_id'])\n",
    "        own_reputation = read_reputation(self.id)\n",
    "\n",
    "        with BID_POOL_LOCK:\n",
    "          condition = (BID_POOL['round'] == CURRENT_ROUND) & (BID_POOL['agent_id'] == self.id) & (BID_POOL['auctioneer_id'] == message['message_body']['auctioneer_id'])\n",
    "          BID_POOL.loc[condition, 'winner'] = winner\n",
    "\n",
    "        task_args = message['message_body']['task_args']\n",
    "        # Check if auction winner\n",
    "        if winner:\n",
    "          print(f'  Client {self.id:>{3}}:  is the auction winner!')\n",
    "          # Perform the offloading task\n",
    "          self.fit_other(task_args)\n",
    "        else:\n",
    "          self.is_available = True\n",
    "\n",
    "    else:\n",
    "      print('ERRONEOUS MESSAGE STRUCTURE...', message, '\\n')\n",
    "\n",
    "\n",
    "  def get_parameters(self, as_list=False):\n",
    "    \"\"\"Get the local model parameters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    as_list : bool\n",
    "        Whether to return a list or a dictionary.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    self.net.state_dict() : OrderedDict or List\n",
    "        Local model parameters.\n",
    "    \"\"\"\n",
    "    if as_list:\n",
    "      return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
    "    else :\n",
    "      return self.net.state_dict()\n",
    "\n",
    "\n",
    "  def set_parameters(self, parameters):\n",
    "    \"\"\"Updates the local model parameters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameters : OrderedDict\n",
    "        Parameters to load to current model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     \"\"\"\n",
    "    self.net.load_state_dict(parameters, strict=True)\n",
    "\n",
    "\n",
    "  def fit(self, parameters=None):\n",
    "    \"\"\"Performs local model training\n",
    "    Parameters\n",
    "    ----------\n",
    "    parameters : OrderedDict\n",
    "        Model weights to load before strating local training.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    self.net.state_dict() : OrderedDict\n",
    "        Local model weights after training.\n",
    "    dataset_size : int\n",
    "        Size of local dataset.\n",
    "    local_loss : List[float]\n",
    "        Local training loss history (size is the number of local epochs).\n",
    "    local_acc : List[float]\n",
    "        Local training accuracy history.\n",
    "    \"\"\"\n",
    "    self.is_available = False           # The client is no longer available\n",
    "    global OFFLOADING_PROB\n",
    "    global TOTAL_OFFLOADING\n",
    "    global DATA_UNIT_SIZE\n",
    "    global MODEL_WEIGHTS_SIZE\n",
    "    global GLOBAL_MODEL_HOLDER\n",
    "    global MODEL_POOL, MODEL_POOL_LOCK, MODELS_PATH\n",
    "\n",
    "    print(f'  Client {self.id:>{3}}: started local training...')\n",
    "    # print(f'Weights of client {self.id} are : {self.get_parameters()}....')\n",
    "\n",
    "    # Will an offloading event occur during training\n",
    "    offload_event = (random.Random().random() < OFFLOADING_PROB)\n",
    "    epochs = random.randint(0, self.epochs-1) if offload_event else self.epochs\n",
    "    # Perform local training\n",
    "    if not (parameters == None):\n",
    "      self.set_parameters(parameters)\n",
    "\n",
    "    # Simulate hardware heterogeneity\n",
    "    time.sleep(random.uniform(10, 20))\n",
    "    # Start training\n",
    "    self.train_loss, self.train_acc = train(\n",
    "        self.net,\n",
    "        self.trainloader,\n",
    "        epochs=epochs,\n",
    "        learning_rate=self.learning_rate,\n",
    "    )\n",
    "    local_loss, local_acc = test(self.net, self.valloader)\n",
    "    self.val_loss = local_loss\n",
    "    self.val_acc = local_acc\n",
    "\n",
    "    # If offloading event\n",
    "    if offload_event:\n",
    "      TOTAL_OFFLOADING  += 1\n",
    "      print(f'  Client {self.id:>{3}}: Offloading event...')\n",
    "      # Launch auction with remaining number of epochs\n",
    "      self.launch_auction(self.epochs-epochs)\n",
    "    else:\n",
    "      # Record task cost into blockchain\n",
    "      self.is_available = True\n",
    "      self.completed_train = True\n",
    "      process_time = training_time(self.get_data_size()*100, self.cpu_cycles, self.frequency, self.epochs)\n",
    "      if self.id == GLOBAL_MODEL_HOLDER.id:\n",
    "        # Generate some random client_idx for tests, ALL COMM TIMES WILL BE CALCULATED DIFFERENTLY ONCE BC IN INTRODUCED\n",
    "        random_idx = random.choice([x for x in range(1, NUM_CLIENTS) if x != self.id])\n",
    "        comm_time = communication_time(MODEL_WEIGHTS_SIZE, self.power, self.coordinates, selected_clients[random_idx].coordinates)\n",
    "      else:\n",
    "        comm_time = communication_time(MODEL_WEIGHTS_SIZE, self.power, self.coordinates, GLOBAL_MODEL_HOLDER.coordinates)\n",
    "      # Store task details\n",
    "      process_energy = computation_energy(self.capacitance, self.frequency, process_time)\n",
    "      comm_energy = communication_energy(self.power, comm_time)\n",
    "      record_to_blockchain([CURRENT_ROUND, self.id, self.id, 'train', process_time, comm_time, process_energy, comm_energy])\n",
    "\n",
    "      # Store model details\n",
    "      with MODEL_POOL_LOCK:\n",
    "        model_id = len(MODEL_POOL.index.to_list())\n",
    "        torch.save(self.get_parameters(), f'{MODELS_PATH}/{model_id}.pth')\n",
    "\n",
    "\n",
    "        MODEL_POOL = pd.concat([MODEL_POOL, pd.DataFrame({\n",
    "            'round': [CURRENT_ROUND],\n",
    "            'level': [1],\n",
    "            'owner' : [self.id],\n",
    "            'trainer': [self.id],\n",
    "            'submodels_id':[[]],\n",
    "            'aggregators': [[]],\n",
    "            'aggregated': [False],\n",
    "            'validators': [[]],\n",
    "            'validation_score': [0],\n",
    "            'lock': [False]\n",
    "        })], ignore_index=True)\n",
    "        # print(f\"  Client: {self.id}: Releasing MODEL_POOL_LOCK..\")\n",
    "      print(f'  Client {self.id:>{3}}: completed local training...')\n",
    "\n",
    "      time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "  def evaluate(self, owner_id, weights):\n",
    "    \"\"\"Evaluate other clients models\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Validation score.\n",
    "    \"\"\"\n",
    "    global selected_clients\n",
    "    # Calculate test accuracy using owner's weights and self.valloader\n",
    "    self.net.load_state_dict(weights)\n",
    "    _, accuracy = test(self.net, self.valloader)\n",
    "    for client in selected_clients:\n",
    "      if client.id == owner_id:\n",
    "        break\n",
    "    owner_acc = client.val_acc\n",
    "    # print(f'accuracy {accuracy}')\n",
    "    # print(f'val accuracy {client.val_acc}')\n",
    "    validation_score = 1 if accuracy >= owner_acc else 1 - (np.abs(accuracy - owner_acc) / 100)\n",
    "    # Save task details\n",
    "    process_time   = validation_time(self.get_data_size() * 100, self.cpu_cycles, self.frequency)\n",
    "    comm_time      = communication_time(MODEL_WEIGHTS_SIZE, self.power, self.coordinates, self.coordinates)\n",
    "    process_energy = computation_energy(self.capacitance, self.frequency, process_time)\n",
    "    comm_energy    = communication_energy(self.power, comm_time)\n",
    "    record_to_blockchain([CURRENT_ROUND, self.id, self.id, 'val', process_time, comm_time, process_energy, comm_energy])\n",
    "    return validation_score\n",
    "\n",
    "\n",
    "  def scale_model_weights(self, weights, factor):\n",
    "    scaled_weights = copy.deepcopy(weights)\n",
    "    for k in scaled_weights.keys():\n",
    "      scaled_weights[k] = factor * scaled_weights[k]\n",
    "\n",
    "    return scaled_weights\n",
    "\n",
    "\n",
    "  def fedavg(self, scaled_weights_list):\n",
    "    w_avg = copy.deepcopy(scaled_weights_list[0])\n",
    "    for k in w_avg.keys():\n",
    "      tmp = torch.zeros_like(scaled_weights_list[0][k], dtype = torch.float32)\n",
    "      for i in range(len(scaled_weights_list)):\n",
    "        tmp += scaled_weights_list[i][k]\n",
    "      w_avg[k].copy_(tmp)\n",
    "    return w_avg\n",
    "\n",
    "\n",
    "\n",
    "  def aggregate(self, models_idxs):\n",
    "    global MODEL_POOL, MODEL_POOL_LOCK\n",
    "    global MODELS_PATH\n",
    "    global MODEL_WEIGHTS_SIZE\n",
    "    client_w = []\n",
    "    factor_w = []\n",
    "    level = 0\n",
    "    aggregators = []\n",
    "    # Get models and scale them\n",
    "    for model_id in models_idxs:\n",
    "      time.sleep(random.uniform(10, 20))\n",
    "      client_w.append(torch.load(f'{MODELS_PATH}/{model_id}.pth'))\n",
    "      # Scale only local models weights\n",
    "      if MODEL_POOL.loc[model_id, 'level'] == 1:\n",
    "        factor_w.append(1/ NUM_CLIENTS)\n",
    "      else:\n",
    "        factor_w.append(1)\n",
    "      level += MODEL_POOL.loc[model_id, 'level']\n",
    "      if MODEL_POOL.at[model_id, 'aggregators'] != []:\n",
    "        aggregators = aggregators + MODEL_POOL.at[model_id, 'aggregators']\n",
    "    scaled_weights_list = [self.scale_model_weights(weights, factor) for weights, factor in zip(client_w, factor_w)]\n",
    "    # Aggregate scaled weights\n",
    "    average_weights = self.fedavg(scaled_weights_list)\n",
    "    aggregators.append(self.id)\n",
    "    # Save aggregated model information\n",
    "    with MODEL_POOL_LOCK:\n",
    "      # Save and share aggregated model\n",
    "      new_model_id = len(MODEL_POOL.index)\n",
    "      torch.save(average_weights, f'{MODELS_PATH}/{new_model_id}.pth')\n",
    "\n",
    "      MODEL_POOL = pd.concat([MODEL_POOL, pd.DataFrame({\n",
    "          'round': [CURRENT_ROUND],\n",
    "          'level': [level],\n",
    "          'owner': [None],\n",
    "          'trainer': [None],\n",
    "          'submodels_id': [models_idxs],\n",
    "          'aggregators': [aggregators],\n",
    "          'aggregated': [False],\n",
    "          'validators': [[]],\n",
    "          'validation_score': [0],\n",
    "          'lock': [False]\n",
    "      })], ignore_index=True)\n",
    "\n",
    "      print(f'  Client {self.id:>{3}}: Model {new_model_id:>{5}} aggregated..')\n",
    "      for model_id in models_idxs:\n",
    "        MODEL_POOL.at[model_id, 'aggregated'] = True\n",
    "        MODEL_POOL.at[model_id, 'lock'] = False\n",
    "      # print(f'  Client {self.id}: Releasing MODEL_POOL_LOCK..')\n",
    "      # Save task details\n",
    "      process_time   = aggregation_time(len(models_idxs), MODEL_WEIGHTS_SIZE, self.cpu_cycles, self.frequency)\n",
    "      comm_time      = communication_time(MODEL_WEIGHTS_SIZE, self.power, self.coordinates, self.coordinates)\n",
    "      process_energy = computation_energy(self.capacitance, self.frequency, process_time)\n",
    "      comm_energy    = communication_energy(self.power, comm_time)\n",
    "      record_to_blockchain([CURRENT_ROUND, self.id, self.id, 'agg', process_time, comm_time, process_energy, comm_energy])\n",
    "\n",
    "\n",
    "  def send_message(self, receiver, message_type, message_body):\n",
    "    \"\"\"Send message to other clients\n",
    "    Parameters\n",
    "    ----------\n",
    "    receiver : Client\n",
    "        Address of the receiver\n",
    "    message_type : MSG_TYPE\n",
    "        Type of the message to send\n",
    "    message_body : dict\n",
    "        Message content, it depends on the message type\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    # Simulate hardware heterogeneity\n",
    "    time.sleep(random.uniform(0.1, 1))\n",
    "    # Use mutex for exclusive access to the client's buffer\n",
    "    with receiver.buffer_mutex:\n",
    "      receiver.buffer.append({\n",
    "          'message_type' : message_type,\n",
    "          'message_body' : message_body\n",
    "      })\n",
    "      time.sleep(1)\n",
    "    # Notify the client\n",
    "    with receiver.notification_mutex:\n",
    "      receiver.notification.set()\n",
    "      time.sleep(1)\n",
    "\n",
    "\n",
    "  def fit_other(self, task_args):\n",
    "    \"\"\"Performs other client's local training task (offloaded task).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task_args : Tuple[int, int, OrderedDict, DataLoader]\n",
    "        Offloaded local task with sender id, remaining epochs, local weights and local dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    global MODEL_POOL_LOCK, MODEL_POOL\n",
    "    # Extract task information\n",
    "    sender_id, remaining_epochs, weights, data = task_args\n",
    "    for sender in selected_clients:\n",
    "      if sender.id == sender_id:\n",
    "        break\n",
    "    print(f\"  Client {self.id:>{3}}: starting local training of client {sender_id:>{3}}'s offloaded task.. \")\n",
    "    # Perform training of other client's model\n",
    "    self.set_parameters(copy.deepcopy(weights))\n",
    "    time.sleep(random.uniform(1, 5))      # For hardware homogeneity\n",
    "    sender.train_loss, sender.train_acc = train(\n",
    "        self.net,                         # Created model with other client's local parameters\n",
    "        data,                             # Pass other client's dataloader\n",
    "        epochs = remaining_epochs,        # Remaining number of epochs\n",
    "        learning_rate = sender.learning_rate\n",
    "    )\n",
    "    local_loss, local_acc = test(self.net, sender.valloader)\n",
    "    sender.val_loss = local_loss\n",
    "    sender.val_acc = local_acc\n",
    "    # Client is now available\n",
    "    self.is_available = True\n",
    "\n",
    "    process_time = training_time(self.get_data_size() * 100, self.cpu_cycles, self.frequency, self.epochs)\n",
    "    comm_time = communication_time(sender.get_data_size() * DATA_UNIT_SIZE + 2 * MODEL_WEIGHTS_SIZE, self.power, self.coordinates, sender.coordinates)\n",
    "    process_energy = computation_energy(self.capacitance, self.frequency, process_time)\n",
    "    comm_energy = communication_energy(self.power, comm_time)\n",
    "    record_to_blockchain([CURRENT_ROUND, sender.id, self.id, 'train', process_time, comm_time, process_energy, comm_energy])\n",
    "\n",
    "    with MODEL_POOL_LOCK:\n",
    "      # Save local models weights\n",
    "      torch.save(self.get_parameters(), f'{MODELS_PATH}/{len(MODEL_POOL.index)}.pth')\n",
    "\n",
    "      MODEL_POOL = pd.concat([MODEL_POOL, pd.DataFrame({\n",
    "          'round': [CURRENT_ROUND],\n",
    "          'level': [1],\n",
    "          'owner' : [sender.id],\n",
    "          'trainer': [self.id],\n",
    "          'submodels_id': [[]],\n",
    "          'aggregators': [[]],\n",
    "          'aggregated': [False],\n",
    "          'validators': [[]],\n",
    "          'validation_score': [0],\n",
    "          'lock': [False]\n",
    "      })], ignore_index=True)\n",
    "      # print(f\"  Client: {self.id}: Releasing MODEL_POOL_LOCK..\")\n",
    "    print(f\"  Client {self.id:>{3}}: completing local training of client {sender_id:>{3}}'s offloaded task..\")\n",
    "    sender.completed_train = True\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "  def launch_auction(self, remaining_epochs, bid_upper_limit=0.2):\n",
    "    \"\"\"Launch auction game for task offloading.\n",
    "    Parameters\n",
    "    ----------\n",
    "    remaining_epochs : int\n",
    "        Remaining number of local epochs.\n",
    "    \"\"\"\n",
    "    global OFFLOADING_TOKEN\n",
    "    global CURRENT_ROUND, NUM_CLIENTS\n",
    "    global AUCTION_OFFER_KEYS\n",
    "    global AUCTION_REP_KEYS\n",
    "    global LR_MODEL\n",
    "    global REPUTATION_DATA\n",
    "    global DATA_UNIT_SIZE\n",
    "    global env\n",
    "    global TASK_DROP\n",
    "\n",
    "    receivers = []\n",
    "    # Allows to perform only one auction at a time\n",
    "    with OFFLOADING_TOKEN:\n",
    "      # Collect available clients\n",
    "      while(len(receivers) < 2):\n",
    "        time.sleep(2)\n",
    "        receivers = [client for client in selected_clients if (client.id != self.id and client.is_available and client.is_active)]\n",
    "      # Select some of the receivers to reduce simulation time\n",
    "      # receivers = receivers[:min(len(receivers), NUM_CLIENTS//2)]\n",
    "      random_indices = random.sample([r.id for r in receivers], min(len(receivers), NUM_CLIENTS//2))\n",
    "      receivers = [rec for rec in receivers if rec.id in random_indices]\n",
    "\n",
    "      print(f'  Client {self.id:>{3}}: Auction receivers collected.... {[rec.id for rec in receivers]}')\n",
    "      # Compose offloading offer/request\n",
    "      task_info = {'dataset_size' : len(self.trainloader.dataset), 'remaining_epochs' : remaining_epochs}\n",
    "      print(f'  Client {self.id:>{3}}: Preparing auction offer....')\n",
    "      reputation = REPUTATION_DATA.loc[(REPUTATION_DATA['round'] == CURRENT_ROUND - 1) & (REPUTATION_DATA['client_id'] == self.id)][['data_quality_norm', 'resource_contribution_norm', 'offloading_history', 'validation_score_norm']].values[0]\n",
    "\n",
    "      sharing_portion = 0\n",
    "      if CURRENT_ROUND >= 2:\n",
    "        sharing_portion = BC.loc[BC['round'] >= 1][['executer_per']].mean()[0]\n",
    "        noise = random.uniform(0, sharing_portion/2)\n",
    "        original_portion = sharing_portion\n",
    "        sharing_portion -= noise\n",
    "        print(f'  Client {self.id:>{3}}: Profit portion offered: {sharing_portion}')\n",
    "\n",
    "      if CURRENT_ROUND == 1 or sharing_portion == 0:\n",
    "        sharing_portion = random.uniform(0, 1) /(NUM_CLIENTS*5)  #* REPUTATION_DATA.loc[(REPUTATION_DATA['round'] == CURRENT_ROUND-1) & (REPUTATION_DATA['client_id'] == self.id)][['profit_per']].values[0][0]\n",
    "        original_portion = sharing_portion\n",
    "        print(f'  Client {self.id:>{3}}: Profit portion offered: {sharing_portion}')\n",
    "\n",
    "      offloading_offer = {\n",
    "          'task_info' : task_info,\n",
    "          'sharing_portion' : sharing_portion\n",
    "      }\n",
    "      auction_offer_values = [time.time(), TOTAL_OFFLOADING+1, CURRENT_ROUND, self.id, offloading_offer]\n",
    "      offloading_request = {key: value for key, value in zip(AUCTION_OFFER_KEYS, auction_offer_values)}\n",
    "      print(f'  Client {self.id:>{3}}: Sending offloading requests....')\n",
    "      # Send offloading request to available nodes\n",
    "      for i in range(len(receivers)):\n",
    "        self.send_message(receivers[i], MSG_TYPE.OFF_REQ, offloading_request)\n",
    "      time.sleep(2)\n",
    "      auction_bids = []\n",
    "\n",
    "      # Collect bids\n",
    "      # TODO Add a waiting limit befire the client drops off\n",
    "      while len(auction_bids) < len(receivers):\n",
    "        time.sleep(2)\n",
    "        if not len(self.buffer) == 0:\n",
    "          with self.buffer_mutex:\n",
    "            for message in self.buffer:\n",
    "              if message['message_type'] == MSG_TYPE.BID:\n",
    "                auction_bids.append(message)\n",
    "            self.buffer = []\n",
    "\n",
    "      print(f'  Client {self.id:>{3}}: Selecting auction winner...')\n",
    "      # Select the auction winner (greedy selection)\n",
    "      auc_reputation = read_reputation(self.id)\n",
    "      all_reputation = [read_reputation(message['message_body']['bidder_ID']) for message in auction_bids]\n",
    "\n",
    "      # Get the auctioneer's utility corresponsing to each bid\n",
    "      epsilon = 10 * random.uniform(0, original_portion)\n",
    "      print(f'  Client {self.id:>{3}}: Bid limit is {sharing_portion+epsilon}...')\n",
    "      # Filter bids\n",
    "      filtered_bids = [(auction_bids[i]['message_body']['bid'] < sharing_portion+epsilon) for i in range(len(auction_bids))]\n",
    "      if any(filtered_bids):\n",
    "        scores = [get_reputation_score(auc_reputation[0], all_reputation[i][1], auc_reputation[2], all_reputation[i][3])[0] for i in range(len(auction_bids))]\n",
    "        print(f'scores {scores}')\n",
    "        b = np.log10(sum(scores)/len(scores))\n",
    "        correct_bids = [auction_bids[i]['message_body']['bid'] for i in range(len(auction_bids)) if filtered_bids[i]]\n",
    "        a = np.log10(sum(correct_bids)/len(correct_bids))\n",
    "        print(f'a {a}')\n",
    "        print(f'b {b}')\n",
    "        rescaled_bids = [auction_bids[i]['message_body']['bid'] * 10**(b-a) for i in range(len(auction_bids))]\n",
    "        print(f'rescaled_bids {rescaled_bids}')\n",
    "        utilities     = [(5/6*scores[i]) - (1/6*rescaled_bids[i]) if filtered_bids[i] else -10000 for i in range(len(auction_bids))]\n",
    "        # utilities     = [get_reputation_score(auc_reputation[0], all_reputation[i][1], auc_reputation[2], all_reputation[i][3])[0] if filtered_bids[i] else -10000 for i in range(len(auction_bids))]\n",
    "        print(f\"Utilities: {[(auction_bids[i]['message_body']['bidder_ID'], utilities[i]) for i in range(len(auction_bids))]}\")\n",
    "        winner_idx = np.argmax(np.array(utilities))\n",
    "        accepted_bid = auction_bids[int(winner_idx)]\n",
    "        rejected_bids = [bid for bid in auction_bids if bid != accepted_bid]\n",
    "        task_args = (self.id, remaining_epochs, self.get_parameters(), self.trainloader)\n",
    "        winner_reputation = all_reputation[int(winner_idx)]\n",
    "        winner_id = accepted_bid['message_body']['bidder_ID']\n",
    "        composed_reputation = [auc_reputation[0], winner_reputation[1], auc_reputation[2], winner_reputation[3]]\n",
    "        # Compose auction response messages content\n",
    "        # TODO: if second price auction select the next higher bid for payment\n",
    "        portion_to_pay = accepted_bid['message_body']['bid']\n",
    "        print(f'  Client {self.id:>{3}}: Portion to pay the auction winner: {portion_to_pay}...')\n",
    "        ['timestamp', 'auction_ID', 'round', 'auctioneer_id', 'composed_reputation', 'bid', 'true_action', 'payment', 'task_args']\n",
    "\n",
    "        auction_winner_values = [time.time(), TOTAL_OFFLOADING+1, CURRENT_ROUND, self.id, composed_reputation, accepted_bid['message_body']['bid'], accepted_bid['message_body']['true_action'], portion_to_pay, task_args]  #  for the auction winner\n",
    "      else:\n",
    "        winner_id = -1\n",
    "        composed_reputation = [auc_reputation[0], 0, auc_reputation[2], 0]\n",
    "        print(f'  Client {self.id:>{3}}: No winner in this auction game...')\n",
    "        TASK_DROP[CURRENT_ROUND-1] = TASK_DROP[CURRENT_ROUND-1] + 1\n",
    "\n",
    "      # Send auction responses\n",
    "      for i, client in enumerate(receivers):\n",
    "        if winner_id == client.id:\n",
    "          self.send_message(client, MSG_TYPE.OFF_REP, {\n",
    "              key: value for key, value in zip(AUCTION_REP_KEYS, auction_winner_values)\n",
    "          })\n",
    "        else:\n",
    "          self.send_message(client, MSG_TYPE.OFF_REP, {\n",
    "              key: value for key, value in zip(AUCTION_REP_KEYS, [time.time(), TOTAL_OFFLOADING+1, CURRENT_ROUND, self.id, composed_reputation, auction_bids[i]['message_body']['bid'], auction_bids[i]['message_body']['true_action'], 0, None])\n",
    "          })\n",
    "\n",
    "      # The client is disconnected\n",
    "      self.is_active = False\n",
    "      print(f'  Client {self.id:>{3}}: Auction completed..')\n",
    "      self.offload = True\n",
    "      if not any(filtered_bids):\n",
    "        self.completed_train = True\n",
    "      time.sleep(1)\n",
    "\n",
    "\n",
    "  def place_bid(self, offer):\n",
    "    \"\"\"Place a bid in a given offloading auction.\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bid : float\n",
    "        The profit portion that this bidder is willing to receive from the auctioneer.\n",
    "    \"\"\"\n",
    "    global env\n",
    "    # global AGENT_LOCK, DDPG_AGENT, REPLAY_MEMORY\n",
    "    global ou_noise\n",
    "\n",
    "    # with AGENT_LOCK:\n",
    "    raw_obs = env.get_obs(self.id)\n",
    "    # print(f'Raw obs: {raw_obs}')\n",
    "    # observation = torch.Tensor([v for _,v in raw_obs.items()]).to(device)\n",
    "    observation = torch.Tensor(raw_obs).to(device)\n",
    "    action = self.ddpg_agent.calc_action(observation, ou_noise)\n",
    "    self.ddpg_agent.decay_exploration()\n",
    "    action = action.cpu().numpy()[0]\n",
    "    bid = action\n",
    "    # ReLu output in [-1,1] convert to [0, 1]\n",
    "    # bid = (bid +  1) / 2\n",
    "    # if bid < offer['sharing_portion']:\n",
    "    # if bid < 0:\n",
    "    #   bid = 0\n",
    "    return bid, action\n",
    "\n",
    "\n",
    "  def get_data_size(self):\n",
    "    \"\"\"Get the size of local dataset.\n",
    "    \"\"\"\n",
    "    return len(self.trainloader.dataset)  # There is a difference between len(trainloader) and len(trainloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Jsz23cbjkX1"
   },
   "source": [
    "### Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSJM4-PZCFNj"
   },
   "outputs": [],
   "source": [
    "# Network class\n",
    "import traceback\n",
    "\n",
    "class Network:\n",
    "  \"\"\"Federated Learning Network\n",
    "  Functions included in this class are to be executed in a completely distributed fashion through smart contracts\"\"\"\n",
    "\n",
    "  def __init__(self, num_clients, batch_size, testloader):\n",
    "    self.net = Net().to(device)\n",
    "    self.num_clients = num_clients\n",
    "    self.batch_size = batch_size\n",
    "    self.testloader = testloader\n",
    "\n",
    "\n",
    "  def select_clients(self, comm_round, selected_clients, threshold=0):\n",
    "    \"\"\"Clients are selected according to their respective reputation scores.\n",
    "    Parameters\n",
    "    ----------\n",
    "    comm_round : int\n",
    "        Current communication round.\n",
    "    threshold : float\n",
    "        Clients with reputation score under this threshold are eliminated from the next round.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    selected_clients_idx : List[int]\n",
    "        List of selected clients indices.\n",
    "    \"\"\"\n",
    "    global REPUTATION_DATA\n",
    "    # np.random.seed(comm_round)      # Random selection\n",
    "    # selected_clients_idx = np.random.choice(np.arange(self.num_clients), np.round(self.num_clients * portion), replace = False)\n",
    "    selected_clients_idx = []\n",
    "    for i in range(len(selected_clients)):\n",
    "      reputation_score = REPUTATION_DATA[(REPUTATION_DATA['round'] == comm_round-1) & (REPUTATION_DATA['client_id'] == selected_clients[i].id)]['reputation_score'].values[0]\n",
    "      if reputation_score >= threshold:\n",
    "        selected_clients_idx.append(i)\n",
    "\n",
    "    return selected_clients_idx\n",
    "\n",
    "\n",
    "  def launch_task(self, comm_rounds, learning_rate, epochs, portion = 1, verbose = 1, verbose_test = 1):\n",
    "    \"\"\"Launch of federated task (the whole FL training process).\n",
    "    Parameters\n",
    "    ----------\n",
    "    comm_rounds : int\n",
    "        Number of communication rounds.\n",
    "    learning_rate : float\n",
    "    portion : float\n",
    "        Portion of clients to select for participating.\n",
    "    epochs : int\n",
    "        Number of local epochs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    net.state_dict() : OrderedDict\n",
    "        Global model parameters after the end of learning.\n",
    "    accuracy : float\n",
    "        Global model accuracy on test data.\n",
    "    loss : float\n",
    "        Global model loss.\n",
    "     \"\"\"\n",
    "    # Learning status flags\n",
    "    global CURRENT_ROUND\n",
    "    global NUM_CLIENTS\n",
    "    global END_ROUND_LOCK\n",
    "    global END_ROUND\n",
    "    global END_TASK\n",
    "    # List of clients\n",
    "    global clients\n",
    "    global selected_clients\n",
    "    global GLOBAL_MODEL_HOLDER\n",
    "    global MODEL_WEIGHTS_SIZE\n",
    "\n",
    "    global REPUTATION_DATA\n",
    "    global RHO_MAX\n",
    "    global LR_MODEL\n",
    "    global MODEL_POOL, MODELS_PATH\n",
    "\n",
    "    global REPLAY_MEMORY, DRL_BATCH_SIZE, DDPG_AGENT\n",
    "    global MEAN_REWARD, MEAN_REWARD_LOCK, BIDDER_UTILITY\n",
    "\n",
    "    global env, ou_noise\n",
    "    global TOTAL_REPUTATION\n",
    "    global GLOBAL_ACCURACY\n",
    "    global BID_POOL, DDPG_AGGREGATED, DDPG_CHECK\n",
    "    global ACTOR_LOSS, CRITIC_LOSS\n",
    "    global TASK_DROP, TASK_DROP_RATE\n",
    "\n",
    "    accuracy = []\n",
    "    loss = []\n",
    "    # self.net.train()\n",
    "\n",
    "    # To nomalize reputation data columns (using MinMax normalization)\n",
    "    columns_to_normalize = ['data_quality', 'resource_contribution', 'validation_score']\n",
    "    columns_normalized = ['data_quality_norm', 'resource_contribution_norm', 'validation_score_norm']\n",
    "\n",
    "    net = Net().to(device)\n",
    "    global_weights = net.state_dict()\n",
    "    MODEL_WEIGHTS_SIZE = sum(p.numel() * p.element_size() for p in global_weights.values())\n",
    "\n",
    "\n",
    "    MODEL_POOL = pd.concat([MODEL_POOL, pd.DataFrame({\n",
    "        'round': [0],\n",
    "        'level': [NUM_CLIENTS],\n",
    "        'owner' : [None],\n",
    "        'trainer': [None],\n",
    "        'submodels_id': [[]],\n",
    "        'aggregators': [[]],\n",
    "        'aggregated': [False],\n",
    "        'validators': [[]],\n",
    "        'validation_score': [0],\n",
    "        'lock': [True]\n",
    "    })], ignore_index=True)\n",
    "    torch.save(global_weights, f'{MODELS_PATH}/0.pth')\n",
    "\n",
    "\n",
    "    print(f'Launch of FL task...')\n",
    "    END_TASK = False\n",
    "    time.sleep(2)\n",
    "    # Selceted clients\n",
    "    selected_clients = clients\n",
    "    # For each communication round\n",
    "    with ThreadPoolExecutor(max_workers=len(clients)) as executor:\n",
    "      for round in range(comm_rounds):\n",
    "        CURRENT_ROUND = round + 1\n",
    "        ou_noise.reset()\n",
    "        if(verbose == 1):\n",
    "          print(\"*************************************************************************************************\")\n",
    "          print(\"Communication round : \", CURRENT_ROUND)\n",
    "\n",
    "        ACTOR_LOSS.append([])\n",
    "        # CRITIC_LOSS.append([])\n",
    "        # Select a list of clients idx\n",
    "        if CURRENT_ROUND > 3:\n",
    "          selected_clients_idx = self.select_clients(CURRENT_ROUND, selected_clients)\n",
    "          selected_clients = [selected_clients[i] for i in selected_clients_idx]\n",
    "          NUM_CLIENTS = len(selected_clients)\n",
    "\n",
    "        # TODO Remove this global model holder\n",
    "        GLOBAL_MODEL_HOLDER = selected_clients[int(np.random.choice(np.arange(len(selected_clients))))]\n",
    "\n",
    "        MEAN_REWARD.append([])\n",
    "        BIDDER_UTILITY.append([])\n",
    "        TASK_DROP.append(0)\n",
    "\n",
    "        for client in selected_clients:\n",
    "          client.reset()\n",
    "\n",
    "        if CURRENT_ROUND == 1:\n",
    "          # Initialize reputation vectors randomly\n",
    "          for i, client in enumerate(selected_clients):\n",
    "            mu = random.uniform(0.5, 0.9)\n",
    "            eta = random.uniform(0.5, 0.9)\n",
    "            nu = random.uniform(0.5, 0.9)\n",
    "            reputation_score, _ = get_reputation_score(mu, eta, 1, nu)\n",
    "\n",
    "            try:\n",
    "              REPUTATION_DATA = pd.concat([REPUTATION_DATA, pd.DataFrame({\n",
    "                  'round' : [0],\n",
    "                  'client_id' : [client.id],\n",
    "                  'data_quality' : [mu],\n",
    "                  'resource_contribution' : [eta],\n",
    "                  'offloading_history' : [1.],\n",
    "                  'validation_score' : [nu],\n",
    "                  'performance_index' : [0.],\n",
    "                  'reputation_score' : [reputation_score],\n",
    "                  'profit' : [0.]\n",
    "              })], ignore_index=True)\n",
    "            except Exception as e:\n",
    "              print(f\"Exception in one of the threads: {e}\")\n",
    "              traceback.print_exc()\n",
    "          # Normalize reputation\n",
    "          REPUTATION_DATA_ROUND = REPUTATION_DATA.loc[(REPUTATION_DATA['round'] == 0)]\n",
    "          scaler = MinMaxScaler()\n",
    "          REPUTATION_DATA_ROUND[columns_normalized] = scaler.fit_transform(REPUTATION_DATA_ROUND[columns_to_normalize])\n",
    "\n",
    "          REPUTATION_DATA.loc[(REPUTATION_DATA['round'] == 0)] = REPUTATION_DATA_ROUND\n",
    "        # Set round flag to start local training\n",
    "        with END_ROUND_LOCK:\n",
    "          DDPG_AGGREGATED = False\n",
    "          DDPG_CHECK = False\n",
    "          END_ROUND = False\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Run clients threads\n",
    "        futures = [executor.submit(client.run) for client in selected_clients]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "          try:\n",
    "            result = future.result()\n",
    "          except Exception as e:\n",
    "            print(f\"Exception in one of the threads: {e}\")\n",
    "            traceback.print_exc()\n",
    "        while not END_ROUND:\n",
    "          time.sleep(2)\n",
    "\n",
    "        try:\n",
    "          print(\"All client threads have completed local training...\")\n",
    "          time.sleep(2)\n",
    "          # Get training results of this communication round\n",
    "          dataset_size = [client.get_data_size() for client in selected_clients]\n",
    "          local_loss   = [client.train_loss for client in selected_clients]\n",
    "          local_acc    = [client.train_acc for client in selected_clients]\n",
    "\n",
    "          for i in range(len(dataset_size)):\n",
    "            # if len(local_loss[i]) > 0:\n",
    "            if len(local_loss[i]) > 0:\n",
    "              print(f'  Client: {selected_clients[i].id:>{3}}    Dataset size: {dataset_size[i]}   Train loss: {sum(local_loss[i])/ len(local_loss[i]): .4f}   Train accuracy:  {sum(local_acc[i]) * 100/ len(local_acc[i]): .4f}')\n",
    "            else:\n",
    "              print(f'  Client: {selected_clients[i].id:>{3}}    Dataset size: {dataset_size[i]}   Train loss: {0.0}   Train accuracy:  {0.0}')\n",
    "\n",
    "          # Get global model weights\n",
    "          # New model weights\n",
    "          model_id = MODEL_POOL[MODEL_POOL['round'] == CURRENT_ROUND]['level'].idxmax()\n",
    "          w_new = torch.load(f'{MODELS_PATH}/{model_id}.pth')\n",
    "          # Old model weights\n",
    "          model_id = MODEL_POOL[MODEL_POOL['round'] == CURRENT_ROUND-1]['level'].idxmax()\n",
    "          w_old = torch.load(f'{MODELS_PATH}/{model_id}.pth')\n",
    "\n",
    "          reputation_scores = []\n",
    "          for i, client in enumerate(selected_clients):\n",
    "            # Get reputation vector\n",
    "            reputation_vector = REPUTATION_DATA.loc[(REPUTATION_DATA['round'] == CURRENT_ROUND-1) & (REPUTATION_DATA['client_id'] == client.id)].to_dict(orient='records')[0]\n",
    "            ##### UPDATE CONTRIBUTION\n",
    "            client_records = BC[(BC['round'] == CURRENT_ROUND) & (BC['executer'] == client.id)]\n",
    "            if not client_records.empty:\n",
    "              # Get task summary of client for this round\n",
    "              task_summary = client_records.groupby('task_type').agg(\n",
    "                task_count=('task_type', 'count'),\n",
    "                processing_time=('processing_time', 'sum'),\n",
    "                communication_time=('communication_time', 'sum'),\n",
    "                processing_energy=('processing_energy', 'sum'),\n",
    "                communication_energy=('communication_energy', 'sum'),\n",
    "                ).reset_index()\n",
    "              # Convert to dictionary\n",
    "              task_summary = task_summary.to_dict(orient='records')\n",
    "              eta, c_i = update_resource_contribution(task_summary, reputation_vector['resource_contribution'])\n",
    "            else:\n",
    "              eta, c_i = update_resource_contribution(None, reputation_vector['resource_contribution'])\n",
    "\n",
    "            ##### UPDATE DATA QUALITY\n",
    "            if not MODEL_POOL[(MODEL_POOL['round'] == CURRENT_ROUND) & (MODEL_POOL['owner'] == client.id)].empty:\n",
    "              local_model_id = MODEL_POOL[(MODEL_POOL['round'] == CURRENT_ROUND) & (MODEL_POOL['owner'] == client.id)].index[0]\n",
    "              w_i = torch.load(f'{MODELS_PATH}/{local_model_id}.pth')\n",
    "              mu = update_data_quality(w_old, w_new, w_i, reputation_vector['data_quality'])\n",
    "            else:\n",
    "              mu = reputation_vector['data_quality']\n",
    "\n",
    "            ##### UPDATE OFFLOADING HISTORY\n",
    "            phi      = reputation_vector['offloading_history']\n",
    "            if client.offload:\n",
    "              phi = update_offload_history(phi)\n",
    "\n",
    "            ##### UPDATE VAILDATION SCORE\n",
    "            # Get the validity score if the client is the model owner or if an executer of an offloaded task\n",
    "            if not MODEL_POOL[(MODEL_POOL['round'] == CURRENT_ROUND) & (MODEL_POOL['trainer'] == client.id)].empty:\n",
    "              new_val_score = MODEL_POOL[(MODEL_POOL['round'] == CURRENT_ROUND) & (MODEL_POOL['trainer'] == client.id)]['validation_score'].values.sum()\n",
    "              nu = update_validation_score(new_val_score, reputation_vector['validation_score'])\n",
    "            else:\n",
    "              nu = reputation_vector['validation_score']\n",
    "\n",
    "            REPUTATION_DATA = pd.concat([REPUTATION_DATA, pd.DataFrame({\n",
    "                'round' : [CURRENT_ROUND],\n",
    "                'client_id' : [client.id],\n",
    "                'data_quality' : [mu],\n",
    "                'resource_contribution' : [eta],\n",
    "                'offloading_history' : [phi],\n",
    "                'validation_score' : [nu],\n",
    "                'performance_index' : [c_i],\n",
    "                'profit' : [0]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "          # Normalize reputation\n",
    "          REPUTATION_DATA_ROUND = REPUTATION_DATA.loc[(REPUTATION_DATA['round'] == CURRENT_ROUND)]\n",
    "          scaler = MinMaxScaler()\n",
    "          REPUTATION_DATA_ROUND[columns_normalized] = scaler.fit_transform(REPUTATION_DATA_ROUND[columns_to_normalize])\n",
    "          REPUTATION_DATA.loc[(REPUTATION_DATA['round'] == CURRENT_ROUND)] = REPUTATION_DATA_ROUND\n",
    "\n",
    "          print('Payment....')\n",
    "          # Calculate total payments\n",
    "          new_df = BC.loc[(BC['round'] == CURRENT_ROUND)]\n",
    "          for index, r in new_df.iterrows():\n",
    "            row = r.to_dict()\n",
    "            # Update task data quality\n",
    "            mu_old = REPUTATION_DATA[(REPUTATION_DATA['round'] == CURRENT_ROUND-1) & (REPUTATION_DATA['client_id'] == row['owner'])].to_dict(orient='records')[0]['data_quality']\n",
    "            local_model_id = MODEL_POOL[(MODEL_POOL['round'] == CURRENT_ROUND) & (MODEL_POOL['owner'] == row['owner'])].index[0]\n",
    "            w_i = torch.load(f'{MODELS_PATH}/{local_model_id}.pth')\n",
    "            new_df.at[index, 'data_quality'] = update_data_quality(w_old, w_new, w_i, mu_old)\n",
    "            # Update resource contribution\n",
    "            eta_old = REPUTATION_DATA[(REPUTATION_DATA['round'] == CURRENT_ROUND-1) & (REPUTATION_DATA['client_id'] == row['executer'])].to_dict(orient='records')[0]['resource_contribution']\n",
    "            task_summary = {\n",
    "              'task_count' : 1,\n",
    "              'processing_time' : row['processing_time'],\n",
    "              'communication_time' : row['communication_time'],\n",
    "              'processing_energy' : row['processing_energy'],\n",
    "              'communication_energy' : row['communication_energy']\n",
    "            }\n",
    "            new_df.at[index, 'resource_contribution'], new_df.at[index, 'performance_index'] = update_resource_contribution([task_summary], eta_old)\n",
    "            # Update offloading history\n",
    "            phi = REPUTATION_DATA[(REPUTATION_DATA['round'] == CURRENT_ROUND-1) & (REPUTATION_DATA['client_id'] == row['owner'])].to_dict(orient='records')[0]['offloading_history']\n",
    "            if (row['task_type'] == 'train') and (row['executer'] != row['owner']):\n",
    "              phi = update_offload_history(phi)\n",
    "            new_df.at[index, 'offloading_history'] = phi\n",
    "            # Update validation score\n",
    "            nu_old = REPUTATION_DATA[(REPUTATION_DATA['round'] == CURRENT_ROUND-1) & (REPUTATION_DATA['client_id'] == row['executer'])].to_dict(orient='records')[0]['validation_score']\n",
    "            new_val_score = MODEL_POOL[(MODEL_POOL['round'] == CURRENT_ROUND) & (MODEL_POOL['trainer'] == row['executer']) & (MODEL_POOL['owner'] == row['owner'])].to_dict(orient='records')[0]['validation_score']\n",
    "            new_df.at[index, 'validation_score'] = update_validation_score(new_val_score, nu_old)\n",
    "\n",
    "          BC.loc[(BC['round'] == CURRENT_ROUND)] = new_df\n",
    "          # Normalize reputation\n",
    "          # REPUTATION_DATA_ROUND = REPUTATION_DATA.loc[(REPUTATION_DATA['round'] == CURRENT_ROUND)]\n",
    "          scaler = MinMaxScaler()\n",
    "          new_df[columns_normalized] = scaler.fit_transform(new_df[columns_to_normalize])\n",
    "          BC.loc[(BC['round'] == CURRENT_ROUND)] = new_df\n",
    "\n",
    "          for index, r in new_df.iterrows():\n",
    "            # Calculate the score of each task\n",
    "            row = r.to_dict()\n",
    "            reputation_score, sub_scores = get_reputation_score(row['data_quality_norm'], row['resource_contribution_norm'], row['offloading_history'], row['validation_score_norm'])\n",
    "            new_df.at[index, 'reputation_score'] = reputation_score\n",
    "            new_df.at[index, 'executer_score']   = sub_scores[1] + sub_scores[3]\n",
    "          total_score = new_df[['reputation_score']].sum()[0]\n",
    "\n",
    "          # Calculate profit percentages\n",
    "          for index, r in new_df.iterrows():\n",
    "            row = r.to_dict()\n",
    "            new_df.at[index, 'executer_per'] = (row['executer_score'] / total_score) + 1e-8\n",
    "\n",
    "          BC.loc[(BC['round'] == CURRENT_ROUND)] = new_df\n",
    "\n",
    "          for i, client in enumerate(selected_clients):\n",
    "            # Check first if client has participated in this round tasks\n",
    "            executer_df = BC.loc[(BC['round'] == CURRENT_ROUND) & (BC['executer'] == client.id)]\n",
    "            owner_df    = BC.loc[(BC['round'] == CURRENT_ROUND) & (BC['owner'] == client.id)]\n",
    "            # print(executer_df)\n",
    "            # print(owner_df)\n",
    "            # if not executer_df.empty or not owner_df.empty:\n",
    "            executer_sum = 0\n",
    "            owner_sum = 0\n",
    "            if not executer_df.empty:\n",
    "              executer_sum = executer_df[['executer_score']].sum()[0]\n",
    "            if not owner_df.empty:\n",
    "              owner_sum = (owner_df[['reputation_score']] - owner_df[['executer_score']]).sum()[0]\n",
    "            new_profit = RHO_MAX * (executer_sum + owner_sum)\n",
    "            idx = REPUTATION_DATA[(REPUTATION_DATA['round'] == CURRENT_ROUND) & (REPUTATION_DATA['client_id'] == client.id)].index[0]\n",
    "            REPUTATION_DATA.at[idx, 'profit'] = new_profit\n",
    "            mu = REPUTATION_DATA.at[idx, 'data_quality_norm']\n",
    "            eta = REPUTATION_DATA.at[idx, 'resource_contribution_norm']\n",
    "            phi = REPUTATION_DATA.at[idx, 'offloading_history']\n",
    "            nu = REPUTATION_DATA.at[idx, 'validation_score_norm']\n",
    "            REPUTATION_DATA.at[idx, 'reputation_score'], _ = get_reputation_score(mu, eta, phi, nu)\n",
    "            # # Update recorded data\n",
    "            client.wallet += new_profit\n",
    "\n",
    "          total_reputation_score = REPUTATION_DATA[REPUTATION_DATA['round'] == CURRENT_ROUND]['reputation_score'].sum() / len(REPUTATION_DATA[REPUTATION_DATA['round'] == CURRENT_ROUND]['reputation_score'])\n",
    "          TOTAL_REPUTATION.append(total_reputation_score)\n",
    "          TASK_DROP_RATE.append(TASK_DROP[CURRENT_ROUND-1]/NUM_CLIENTS)\n",
    "          print(f'  Total reputation score: {total_reputation_score}')\n",
    "          # Test global model performance on test dataset\n",
    "          loss_test, _, acc_test = self.test(w_new)\n",
    "\n",
    "          if (verbose_test):\n",
    "            print(\"Communication round : \", round + 1, \", Test accuracy : \", acc_test, \", Test loss : \", loss_test)\n",
    "            print(\"*****************************************************************************************************\")\n",
    "          GLOBAL_ACCURACY.append(acc_test)\n",
    "          accuracy.append(acc_test)\n",
    "          loss.append(loss_test)\n",
    "          # print(f'Reputation data \\n {REPUTATION_DATA}')\n",
    "          print(\"End round...\")\n",
    "\n",
    "\n",
    "          temp = BID_POOL.loc[BID_POOL['round'] == CURRENT_ROUND]\n",
    "          for i, r in temp.iterrows():\n",
    "            row = r.to_dict()\n",
    "            if row['winner'] == True:\n",
    "              fair_payment = BC[(BC['round'] == CURRENT_ROUND) & (BC['owner'] == row['auctioneer_id']) & (BC['executer'] == row['agent_id']) & (BC['task_type'] == 'train')].to_dict(orient='records')[0]['executer_per']\n",
    "            else:\n",
    "              if not BC[(BC['round'] == CURRENT_ROUND) & (BC['owner'] == row['auctioneer_id']) & (BC['task_type'] == 'train')].empty:\n",
    "                fair_payment = BC[(BC['round'] == CURRENT_ROUND) & (BC['owner'] == row['auctioneer_id']) & (BC['task_type'] == 'train')].to_dict(orient='records')[0]['executer_per']\n",
    "              else:\n",
    "                fair_payment = 0.\n",
    "\n",
    "              \n",
    "            auc_reputation = REPUTATION_DATA[(REPUTATION_DATA['round'] == CURRENT_ROUND) & (REPUTATION_DATA['client_id'] == row['agent_id'])][['data_quality_norm', 'resource_contribution_norm', 'offloading_history', 'validation_score_norm']].values[0]\n",
    "            bidder_reputation = REPUTATION_DATA[(REPUTATION_DATA['round'] == CURRENT_ROUND) & (REPUTATION_DATA['client_id'] == row['auctioneer_id'])][['data_quality_norm', 'resource_contribution_norm', 'offloading_history', 'validation_score_norm']].values[0]\n",
    "            # composed_reputation = [auc_reputation[0], bidder_reputation[1], auc_reputation[2], bidder_reputation[3]]\n",
    "            BID_POOL.at[i, 'fair_payment'] = fair_payment\n",
    "\n",
    "          # Save changes\n",
    "          mode = 'a' if i>1 else 'w' \n",
    "          BC[BC['round']==CURRENT_ROUND].to_csv('results/reinforce/BC_50cli_50round_01offprob_8ep_withaucutility_noniid.csv', index=False, mode=mode, header=not (CURRENT_ROUND>1))\n",
    "          REPUTATION_DATA[REPUTATION_DATA['round']==CURRENT_ROUND].to_csv('results/reinforce/REPUTATION_DATA_50cli_50round_01offprob_8ep_withaucutility_noniid.csv', index=False, mode=mode, header=not (CURRENT_ROUND>1))\n",
    "          BID_POOL[BID_POOL['round']==CURRENT_ROUND].to_csv('results/reinforce/BID_POOL_50cli_50round_01offprob_8ep_withaucutility_noniid.csv', index=False, mode=mode, header=not (CURRENT_ROUND>1))\n",
    "          with open('results/reinforce/metrics_50cli_50round_01offprob_8ep_withaucutility_noniid.csv', 'a', newline='') as file:\n",
    "              writer = csv.writer(file)\n",
    "              writer.writerow([CURRENT_ROUND, GLOBAL_ACCURACY[CURRENT_ROUND-1], ACTOR_LOSS[CURRENT_ROUND-1], TOTAL_REPUTATION[CURRENT_ROUND-1], TASK_DROP_RATE[CURRENT_ROUND-1]])\n",
    "            \n",
    "          if len(ACTOR_LOSS[CURRENT_ROUND-1]) > 0:\n",
    "            print(f'Global actor loss : {sum(ACTOR_LOSS[CURRENT_ROUND-1])/len(ACTOR_LOSS[CURRENT_ROUND-1])}')\n",
    "            # print(f'Global critic loss : {sum(CRITIC_LOSS[CURRENT_ROUND-1])/len(CRITIC_LOSS[CURRENT_ROUND-1])}')\n",
    "          print(\"End round and models training...\")\n",
    "          delete_models(MODELS_PATH)\n",
    "        except Exception as e:\n",
    "          print(f\"An exception occurred: {e}\")\n",
    "          traceback.print_exc()\n",
    "\n",
    "      with MEAN_REWARD_LOCK:\n",
    "        MEAN_REWARD = [sum(MEAN_REWARD[i])/len(MEAN_REWARD[i]) for i in range(len(MEAN_REWARD[i]))]\n",
    "      END_TASK = True\n",
    "      print('End of FL task')\n",
    "    return self.net.state_dict(), accuracy, loss\n",
    "\n",
    "\n",
    "  def test(self, weights):\n",
    "    \"\"\" Evaluates global model performance with test dataset \"\"\"\n",
    "    self.net.load_state_dict(weights)\n",
    "    loss, accuracy = test(self.net, self.testloader)\n",
    "    return float(loss), len(self.testloader.dataset), float(accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y74rRnRWAX4o"
   },
   "source": [
    "### DRL for Bidding Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZNBMcpXS5cp"
   },
   "source": [
    "#### Environment Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXjbfzwhpH2n"
   },
   "outputs": [],
   "source": [
    "# Define a Custom Gym Environment\n",
    "class BiddingEnv(gym.Env):\n",
    "  def __init__(self, num_agents=10):\n",
    "    super(BiddingEnv, self).__init__()\n",
    "    self.num_agents = num_agents\n",
    "\n",
    "    # Define the components of the observation space\n",
    "    self.observation_space = spaces.Dict({\n",
    "      # 'bidder_reputation':  spaces.Box(low=0.0, high=1.0, shape=(4,), dtype=float),\n",
    "      # 'auctioneer_reputation': spaces.Box(low=0.0, high=1.0, shape=(4,), dtype=float),\n",
    "      'composed_reputation': spaces.Box(low=0.0, high=1.0, shape=(4,), dtype=float),\n",
    "      'performance_index': spaces.Box(low=0.0, high=100.0, shape=(1,), dtype=float),\n",
    "      'payment': spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=float)\n",
    "    })\n",
    "    # Define action space\n",
    "    self.action_space = spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=float)\n",
    "    # Define state space\n",
    "    self.state_space = spaces.Tuple([self.observation_space] * num_agents)\n",
    "    #Initialize current state\n",
    "    self.current_state = self.reset_()\n",
    "\n",
    "\n",
    "  def get_n_observations(self):\n",
    "    return (\n",
    "      self.observation_space['composed_reputation'].shape[0] +\n",
    "      self.observation_space['performance_index'].shape[0] +\n",
    "      self.observation_space['payment'].shape[0]\n",
    "      # self.observation_space['battery_level'].n\n",
    "    )\n",
    "\n",
    "\n",
    "  def get_action_range(self):\n",
    "    return self.action_space.high - self.action_space.low\n",
    "\n",
    "\n",
    "  def reset_obs(self, agent_id):\n",
    "    # self.set_obs(agent_id, [0, 0, 0, 0], [0, 0, 0, 0], 0., 0.)\n",
    "    self.set_obs(agent_id, [0, 0, 0, 0], 0., 0.)\n",
    "\n",
    "\n",
    "  def reset_(self):\n",
    "    # Reset the environment to the initial state\n",
    "    # super.reset(seed=self.seed)\n",
    "    initial_state = []\n",
    "    for i in range(self.num_agents):\n",
    "      initial_state.append({\n",
    "        # 'bidder_reputation': [0, 0, 0, 0],\n",
    "        # 'auctioneer_reputation': [0, 0, 0, 0],\n",
    "        'composed_reputation': [0, 0, 0, 0],\n",
    "        'performance_index': 0.,\n",
    "        'payment': 0.\n",
    "      })\n",
    "    return initial_state\n",
    "\n",
    "\n",
    "  def set_obs(self, agent_id, bidder_reputation, auctioneer_reputation, c_idx, payment):\n",
    "    self.current_state[agent_id-1] = {\n",
    "        # 'bidder_reputation': bidder_reputation,\n",
    "        # 'auctioneer_reputation': auctioneer_reputation,\n",
    "        'composed_reputation': [auctioneer_reputation[0], bidder_reputation[1], auctioneer_reputation[2], bidder_reputation[3]],\n",
    "        'performance_index':c_idx,\n",
    "        'payment': payment\n",
    "    }\n",
    "\n",
    "\n",
    "  def get_obs(self, agent_id):\n",
    "    # print(self.current_state)\n",
    "    # print(f'current observation {self.current_state[agent_id-1]}....')\n",
    "    current_obs = self.current_state[agent_id-1]\n",
    "    # observation_to_list = list(current_obs['bidder_reputation']) + list(current_obs['auctioneer_reputation']) + [current_obs['performance_index']] + [current_obs['payment']]\n",
    "    observation_to_list = list(current_obs['composed_reputation']) + [current_obs['performance_index']] + [current_obs['payment']]\n",
    "    # print(f'  Get observation {observation_to_list}........')\n",
    "    return observation_to_list\n",
    "\n",
    "\n",
    "  def get_state(self):\n",
    "    return self.current_state\n",
    "\n",
    "\n",
    "  def step_(self, agent_id, winner, bidder_reputation, auctioneer_reputation, c_idx, payment, fair_payment, scaling_factor=1):\n",
    "    \"\"\"\n",
    "    Calculates the next observation and reward given the taken action.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    observation: spaces.Dict\n",
    "        Next observation or state observable by this agent.\n",
    "    reward: float\n",
    "        Reward signal received according to auction result.\n",
    "    done: bool\n",
    "        Whether the episode is done.\n",
    "    info: Dict\n",
    "        Optional dictionary containing additional information about the step.\n",
    "    \"\"\"\n",
    "    global CURRENT_ROUND\n",
    "    global BIDDER_UTILITY_THRESHOLD\n",
    "    global METRICS_LOCK, BIDDER_UTILITY\n",
    "\n",
    "    # Calculate next state\n",
    "\n",
    "    system_utility = self._system_utility(agent_id, bidder_reputation, auctioneer_reputation)\n",
    "    if winner:\n",
    "      if CURRENT_ROUND > 1:\n",
    "        bidder_utility = self._bidder_utility(agent_id, payment, fair_payment)\n",
    "        if bidder_utility == 0:\n",
    "          reward = system_utility * scaling_factor\n",
    "        else:\n",
    "          p_f = bidder_utility\n",
    "          f_p = 1/ bidder_utility\n",
    "          reward = 1/(p_f + f_p) * scaling_factor * 10 + system_utility * scaling_factor\n",
    "\n",
    "        info = {\"agent_id\": agent_id, \"winner\": True, \"bidder_utility\": bidder_utility, \"system_utility\": system_utility}\n",
    "      else:\n",
    "        reward = system_utility * scaling_factor\n",
    "        info = {\"agent_id\": agent_id, \"winner\": True, \"bidder_utility\": 1e-5, \"system_utility\": 1e-5}\n",
    "      print(f'  Client {agent_id:>{3}}: Obtained reward: {reward}')\n",
    "\n",
    "    else:\n",
    "      bidder_utility = payment / (fair_payment+1e-8)\n",
    "      if bidder_utility == 0:\n",
    "        reward = - system_utility * scaling_factor\n",
    "      else:\n",
    "        p_f = bidder_utility\n",
    "        f_p = 1/ bidder_utility\n",
    "        reward = -((p_f + f_p) + 1 / (10*system_utility + 1e-6))\n",
    "        if reward < -5:\n",
    "          reward = -5\n",
    "      info = {\"agent_id\": agent_id, \"winner\": False, \"bidder_utility\": 0, \"system_utility\": 0}\n",
    "        \n",
    "    return self.get_obs(agent_id), reward, False, info\n",
    "\n",
    "\n",
    "\n",
    "  def _bidder_utility(self, agent_id, payment, fair_payment):\n",
    "    global BIDDER_UTILITYY, METRICS_LOCK\n",
    "    profit_made    = payment / (fair_payment+1e-8)\n",
    "    with METRICS_LOCK:\n",
    "      BIDDER_UTILITY[CURRENT_ROUND-1].append(profit_made)\n",
    "    bidder_utility = profit_made\n",
    "    print(f'  Client {agent_id:>{3}}: Bidder utility is {bidder_utility} (payment: {payment} -- fair payment: {fair_payment})...')\n",
    "    return bidder_utility\n",
    "\n",
    "\n",
    "  def _system_utility(self, agent_id, bidder_reputation, auctioneer_reputation):\n",
    "    composed_score, _ = get_reputation_score(auctioneer_reputation[0], bidder_reputation[1], auctioneer_reputation[2], bidder_reputation[3])\n",
    "    bidder_score, _ = get_reputation_score(bidder_reputation[0], bidder_reputation[1], bidder_reputation[2], bidder_reputation[3])\n",
    "    auctioneer_score, _ = get_reputation_score(auctioneer_reputation[0], auctioneer_reputation[1], auctioneer_reputation[2], auctioneer_reputation[3])\n",
    "    # system_utility = 2 * composed_score / (bidder_score + auctioneer_score)\n",
    "    system_utility = composed_score\n",
    "    # print(f'  Client {agent_id:>{3}}: System utility is {system_utility}...')\n",
    "    return system_utility\n",
    "\n",
    "\n",
    "  def render(self):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdliwDB-Ottn"
   },
   "outputs": [],
   "source": [
    "# Register the custom environment\n",
    "from gym.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id='BiddingEnv-v0',\n",
    "    entry_point='__main__:BiddingEnv',\n",
    "    max_episode_steps=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbMYM09cTBy4"
   },
   "source": [
    "#### DRL Agnet Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usViDbIETFQH"
   },
   "outputs": [],
   "source": [
    "# Taken from : https://github.com/schneimo/ddpg-pytorch/tree/master \n",
    "# and modified to suit our application..\n",
    "\n",
    "\n",
    "## Experience Replay Buffer Class\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity=1e3):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = int((self.position + 1) % self.capacity)\n",
    "\n",
    "    def get_last_episode(self, episode_len):\n",
    "        \"\"\"Get the last episode_len elements.\"\"\"\n",
    "        if len(self.memory) < episode_len:\n",
    "          return self.memory[:self.position]\n",
    "        else:\n",
    "          if self.position >= episode_len:\n",
    "            start_index = random.randint(0, self.position - episode_len)\n",
    "            return self.memory[start_index:start_index + episode_len]\n",
    "\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "\n",
    "      # To avoid overfitting on 0-reward experiences, we rebalance\n",
    "      # nonzero_reward_transitions = [t for t in self.memory if t.reward != 0]\n",
    "      nonzero_reward_transitions = [t for t in self.memory if t.reward > 0]\n",
    "      num_nonzero_reward_transitions = len(nonzero_reward_transitions)\n",
    "      zero_reward_transitions = [t for t in self.memory if t.reward <= 0]\n",
    "      num_zero_reward_transitions = len(zero_reward_transitions)\n",
    "      if num_zero_reward_transitions < batch_size // 2:\n",
    "        num_nonzero_reward_transitions = batch_size - num_zero_reward_transitions\n",
    "      elif num_nonzero_reward_transitions < batch_size // 2:\n",
    "        num_zero_reward_transitions = batch_size - num_nonzero_reward_transitions\n",
    "      else:\n",
    "        num_nonzero_reward_transitions = num_zero_reward_transitions = batch_size//2\n",
    "      # Determine the number of transitions with non-zero rewards to include in the batch\n",
    "      selected_nonzero_reward_transitions = random.sample(nonzero_reward_transitions, num_nonzero_reward_transitions)\n",
    "\n",
    "      selected_zero_reward_transitions = random.sample(zero_reward_transitions, num_zero_reward_transitions)\n",
    "      # Combine the selected transitions\n",
    "      selected_transitions = selected_nonzero_reward_transitions + selected_zero_reward_transitions\n",
    "\n",
    "      # Shuffle the selected transitions\n",
    "      random.shuffle(selected_transitions)\n",
    "      # return random.sample(self.memory, batch_size)\n",
    "      return selected_transitions\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "\n",
    "# WEIGHTS_FINAL_INIT = -40e-1\n",
    "# BIAS_FINAL_INIT = -40e-2\n",
    "WEIGHTS_FINAL_INIT = -5e-1\n",
    "BIAS_FINAL_INIT = -5e-2\n",
    "\n",
    "\n",
    "def fan_in_uniform_init(tensor, fan_in=None):\n",
    "    \"\"\"Utility function for initializing actor and critic\"\"\"\n",
    "    if fan_in is None:\n",
    "        fan_in = tensor.size(-1)\n",
    "\n",
    "    w = 1. / np.sqrt(fan_in)\n",
    "    nn.init.uniform_(tensor, -w, w)\n",
    "\n",
    "## Actor class\n",
    "class Actor(nn.Module):\n",
    "  def __init__(self, hidden_size, num_inputs, action_space):\n",
    "    super(Actor, self).__init__()\n",
    "    self.action_space = action_space\n",
    "    num_outputs = action_space.shape[0]\n",
    "    # Layer 1\n",
    "    self.linear1 = nn.Linear(num_inputs, hidden_size[0])\n",
    "    self.ln1 = nn.LayerNorm(hidden_size[0])\n",
    "    # Layer 2\n",
    "    self.linear2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "    self.ln2 = nn.LayerNorm(hidden_size[1])\n",
    "    # Output Layer\n",
    "    self.mu = nn.Linear(hidden_size[1], num_outputs)\n",
    "    # Weight Init\n",
    "    fan_in_uniform_init(self.linear1.weight)\n",
    "    fan_in_uniform_init(self.linear1.bias)\n",
    "    fan_in_uniform_init(self.linear2.weight)\n",
    "    fan_in_uniform_init(self.linear2.bias)\n",
    "    nn.init.uniform_(self.mu.weight, WEIGHTS_FINAL_INIT, 0)\n",
    "    nn.init.uniform_(self.mu.bias, BIAS_FINAL_INIT, 0)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    x = inputs\n",
    "    # Layer 1\n",
    "    x = self.linear1(x)\n",
    "    x = self.ln1(x)\n",
    "    x = F.relu(x)\n",
    "    # Layer 2\n",
    "    x = self.linear2(x)\n",
    "    x = self.ln2(x)\n",
    "    x = F.relu(x)\n",
    "    # Output\n",
    "    # mu = torch.tanh(self.mu(x))\n",
    "    mu = torch.sigmoid(self.mu(x))\n",
    "    return mu\n",
    "\n",
    "\n",
    "## Critic Class\n",
    "class Critic(nn.Module):\n",
    "  def __init__(self, hidden_size, num_inputs, action_space):\n",
    "    super(Critic, self).__init__()\n",
    "    self.action_space = action_space\n",
    "    num_outputs = action_space.shape[0]\n",
    "    # Layer 1\n",
    "    self.linear1 = nn.Linear(num_inputs, hidden_size[0])\n",
    "    self.ln1 = nn.LayerNorm(hidden_size[0])\n",
    "    # Layer 2\n",
    "    # In the second layer the actions will be inserted also\n",
    "    self.linear2 = nn.Linear(hidden_size[0] + num_outputs, hidden_size[1])\n",
    "    self.ln2 = nn.LayerNorm(hidden_size[1])\n",
    "    # Output layer (single value)\n",
    "    self.V = nn.Linear(hidden_size[1], 1)\n",
    "    # Weight Init\n",
    "    fan_in_uniform_init(self.linear1.weight)\n",
    "    fan_in_uniform_init(self.linear1.bias)\n",
    "    fan_in_uniform_init(self.linear2.weight)\n",
    "    fan_in_uniform_init(self.linear2.bias)\n",
    "\n",
    "\n",
    "    nn.init.uniform_(self.V.weight, WEIGHTS_FINAL_INIT, 0)\n",
    "    nn.init.uniform_(self.V.bias, BIAS_FINAL_INIT, 0)\n",
    "\n",
    "  def forward(self, inputs, actions):\n",
    "    x = inputs\n",
    "    # Layer 1\n",
    "    x = self.linear1(x)\n",
    "    x = self.ln1(x)\n",
    "    x = F.relu(x)\n",
    "    # Layer 2\n",
    "    x = torch.cat((x, actions), 1)  # Insert the actions\n",
    "    x = self.linear2(x)\n",
    "    x = self.ln2(x)\n",
    "    x = F.relu(x)\n",
    "    # Output\n",
    "    V = self.V(x)\n",
    "\n",
    "\n",
    "    return V\n",
    "\n",
    "\n",
    "## Target Networks Update Functions\n",
    "def soft_update(target, source, tau):\n",
    "  for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "    target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n",
    "\n",
    "def hard_update(target, source):\n",
    "  for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, hidden_size, action_space):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        num_outputs = action_space.shape[0]\n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size[0])\n",
    "        self.ln1 = nn.LayerNorm(hidden_size[0])\n",
    "        self.linear2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.ln2 = nn.LayerNorm(hidden_size[1])\n",
    "        self.mean_linear = nn.Linear(hidden_size[1], num_outputs)\n",
    "        self.std_linear = nn.Linear(hidden_size[1], num_outputs)\n",
    "\n",
    "        fan_in_uniform_init(self.linear1.weight)\n",
    "        fan_in_uniform_init(self.linear1.bias)\n",
    "        fan_in_uniform_init(self.linear2.weight)\n",
    "        fan_in_uniform_init(self.linear2.bias)\n",
    "        nn.init.uniform_(self.mean_linear.weight, WEIGHTS_FINAL_INIT, 0)\n",
    "        nn.init.uniform_(self.mean_linear.bias, BIAS_FINAL_INIT, 0)\n",
    "\n",
    "        nn.init.uniform_(self.std_linear.weight, WEIGHTS_FINAL_INIT, 0)\n",
    "        nn.init.uniform_(self.std_linear.bias, BIAS_FINAL_INIT, 0)\n",
    "\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.linear1(state)\n",
    "        x = self.ln1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = F.relu(x)\n",
    "        mean = torch.sigmoid(self.mean_linear(x))  # Applying sigmoid activation\n",
    "        std = F.softplus(self.std_linear(x))\n",
    "        return mean, std\n",
    "\n",
    "\n",
    "\n",
    "## DDPG Agent Class\n",
    "class DDPG(object):\n",
    "  def __init__(self, gamma, tau, hidden_size, num_inputs, action_space, exploration_prob=0.9, decay_rate=0.99, checkpoint_dir=None):\n",
    "\n",
    "    self.gamma = gamma\n",
    "    self.action_space = action_space\n",
    "    self.policy_network = PolicyNetwork(num_inputs, hidden_size, action_space).to(device)\n",
    "    self.optimizer = Adam(self.policy_network.parameters(), lr=1e-3)\n",
    "    self.exploration_prob = exploration_prob\n",
    "    self.decay_rate = decay_rate\n",
    "\n",
    "  def calc_action(self, state, action_noise=None):\n",
    "\n",
    "    self.policy_network.eval()\n",
    "    x = state.to(device)\n",
    "    with torch.no_grad():\n",
    "      mean, std = self.policy_network(x)\n",
    "      # Sample from Gaussian Distribution\n",
    "      normal = torch.distributions.Normal(mean, std)\n",
    "      action = normal.sample()\n",
    "      print(f'  Calculating bid... action(bid) wt noise: {action.item()}')\n",
    "      if np.random.rand() < self.exploration_prob:\n",
    "        if action_noise is not None:\n",
    "          noise = torch.Tensor(action_noise.noise()).to(device)\n",
    "          action += noise\n",
    "      action = torch.abs(action)\n",
    "      action = torch.clamp(action, 0, 1)\n",
    "    return action\n",
    "\n",
    "\n",
    "  def update_params(self, batch, epochs=1, agent_id=0):\n",
    "    states  = torch.stack(batch.state).to(device)\n",
    "    actions = torch.stack(batch.action).to(device)\n",
    "    rewards = torch.stack(batch.reward).to(device)\n",
    "\n",
    "    self.optimizer.zero_grad()\n",
    "    mean, std = self.policy_network(states)\n",
    "    normal = torch.distributions.Normal(mean, std)\n",
    "    log_probs = normal.log_prob(actions)\n",
    "    returns = self._calculate_returns(rewards)\n",
    "    loss = -(log_probs * returns).mean()\n",
    "    loss.backward()\n",
    "    self.optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "  def _calculate_returns(self, rewards):\n",
    "    G = torch.zeros_like(rewards)\n",
    "    running_sum = 0\n",
    "    for t in reversed(range(len(rewards))):\n",
    "      running_sum = rewards[t] + self.gamma * running_sum\n",
    "      G[t] = running_sum\n",
    "    return G\n",
    "\n",
    "  def decay_exploration(self):\n",
    "    self.exploration_prob *= self.decay_rate\n",
    "\n",
    "  def save_checkpoint(self, last_timestep, replay_buffer):\n",
    "    \"\"\"\n",
    "    Saving the networks and all parameters to a file in 'checkpoint_dir'\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    last_timestep:\n",
    "        Last timestep in training before saving\n",
    "    replay_buffer:  ReplayMemory\n",
    "        Current replay buffer\n",
    "    \"\"\"\n",
    "    checkpoint_name = self.checkpoint_dir + '/ep_{}.pth.tar'.format(last_timestep)\n",
    "    logger.info('Saving checkpoint...')\n",
    "    checkpoint = {\n",
    "        'last_timestep': last_timestep,\n",
    "        'actor': self.actor.state_dict(),\n",
    "        'critic': self.critic.state_dict(),\n",
    "        'actor_target': self.actor_target.state_dict(),\n",
    "        'critic_target': self.critic_target.state_dict(),\n",
    "        'actor_optimizer': self.actor_optimizer.state_dict(),\n",
    "        'critic_optimizer': self.critic_optimizer.state_dict(),\n",
    "        'replay_buffer': replay_buffer,\n",
    "    }\n",
    "    logger.info('Saving model at timestep {}...'.format(last_timestep))\n",
    "    torch.save(checkpoint, checkpoint_name)\n",
    "    gc.collect()\n",
    "    logger.info('Saved model at timestep {} to {}'.format(last_timestep, self.checkpoint_dir))\n",
    "\n",
    "  def get_path_of_latest_file(self):\n",
    "      \"\"\"\n",
    "      Returns the latest created file in 'checkpoint_dir'\n",
    "      \"\"\"\n",
    "      files = [file for file in os.listdir(self.checkpoint_dir) if (file.endswith(\".pt\") or file.endswith(\".tar\"))]\n",
    "      filepaths = [os.path.join(self.checkpoint_dir, file) for file in files]\n",
    "      last_file = max(filepaths, key=os.path.getctime)\n",
    "      return os.path.abspath(last_file)\n",
    "\n",
    "  def load_checkpoint(self, checkpoint_path=None):\n",
    "    \"\"\"\n",
    "    Saving the networks and all parameters from a given path. If the given path is None\n",
    "    then the latest saved file in 'checkpoint_dir' will be used.\n",
    "\n",
    "    Arguments:\n",
    "        checkpoint_path:    File to load the model from\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if checkpoint_path is None:\n",
    "      checkpoint_path = self.get_path_of_latest_file()\n",
    "\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "      logger.info(\"Loading checkpoint...({})\".format(checkpoint_path))\n",
    "      key = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "      checkpoint = torch.load(checkpoint_path, map_location=key)\n",
    "      # start_timestep = checkpoint['last_timestep'] + 1\n",
    "      start_timestep = checkpoint['last_timestep']\n",
    "      self.actor.load_state_dict(checkpoint['actor'])\n",
    "      self.critic.load_state_dict(checkpoint['critic'])\n",
    "      self.actor_target.load_state_dict(checkpoint['actor_target'])\n",
    "      self.critic_target.load_state_dict(checkpoint['critic_target'])\n",
    "      self.actor_optimizer.load_state_dict(checkpoint['actor_optimizer'])\n",
    "      self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "      replay_buffer = checkpoint['replay_buffer']\n",
    "      gc.collect()\n",
    "      logger.info('Loaded model at timestep {} from {}'.format(start_timestep, checkpoint_path))\n",
    "      return start_timestep, replay_buffer\n",
    "    else:\n",
    "      raise OSError('Checkpoint not found')\n",
    "\n",
    "\n",
    "  def set_eval(self):\n",
    "    \"\"\"\n",
    "    Sets the model in evaluation mode\n",
    "    \"\"\"\n",
    "    self.actor.eval()\n",
    "    self.critic.eval()\n",
    "    self.actor_target.eval()\n",
    "    self.critic_target.eval()\n",
    "\n",
    "  def set_train(self):\n",
    "    \"\"\"\n",
    "    Sets the model in training mode\n",
    "    \"\"\"\n",
    "    self.actor.train()\n",
    "    self.critic.train()\n",
    "    self.actor_target.train()\n",
    "    self.critic_target.train()\n",
    "\n",
    "  def get_network(self, name):\n",
    "    if name == 'Actor':\n",
    "      return self.actor\n",
    "    elif name == 'Critic':\n",
    "      return self.critic\n",
    "    else:\n",
    "      raise NameError('name \\'{}\\' is not defined as a network'.format(name))\n",
    "\n",
    "\n",
    "\n",
    "class NormalizedActions(gym.ActionWrapper):\n",
    "  def action(self, action):\n",
    "    \"\"\"\n",
    "    Normalizes the actions to be in between action_space.high and action_space.low.\n",
    "    If action_space.low == -action_space.high, this is equals to action_space.high*action.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    action\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    Normalized action\n",
    "    \"\"\"\n",
    "\n",
    "    action = (action + 1) / 2  # [-1, 1] => [0, 1]\n",
    "    action *= (self.action_space.high - self.action_space.low)\n",
    "    action += self.action_space.low\n",
    "    return action\n",
    "\n",
    "  def reverse_action(self, action):\n",
    "    \"\"\"\n",
    "    Reverts the normalization\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    action\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    Reverted action\n",
    "    \"\"\"\n",
    "    action -= self.action_space.low\n",
    "    action /= (self.action_space.high - self.action_space.low)\n",
    "    action = action * 2 - 1\n",
    "    return action\n",
    "\n",
    "\n",
    "\n",
    "# From OpenAI Baselines:\n",
    "# https://github.com/openai/baselines/blob/master/baselines/ddpg/noise.py\n",
    "class OrnsteinUhlenbeckActionNoise:\n",
    "  def __init__(self, mu, sigma, theta=.15, dt=1e-2, x0=None):\n",
    "    self.theta = theta\n",
    "    self.mu = mu\n",
    "    self.sigma = sigma\n",
    "    self.dt = dt\n",
    "    self.x0 = x0\n",
    "    self.reset()\n",
    "\n",
    "  def noise(self):\n",
    "    x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt \\\n",
    "        + self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "    self.x_prev = x\n",
    "    return x\n",
    "\n",
    "  def reset(self):\n",
    "    self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "\n",
    "  def __repr__(self):\n",
    "    return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1cQKBk5kJ9m"
   },
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kx58n1DncMs5",
    "outputId": "580d5ae2-cc69-45ae-dcd5-884879d31933"
   },
   "outputs": [],
   "source": [
    "### MAIN PROGRAM\n",
    "\n",
    "## Dataframes Args\n",
    "BC_LOCK = threading.Lock()\n",
    "columns = ['round', 'owner', 'executer', 'task_type', 'processing_time', 'communication_time', 'processing_energy', 'communication_energy', 'data_quality', 'resource_contribution', 'offloading_history', 'validation_score', 'data_quality_norm', 'resource_contribution_norm', 'validation_score_norm', 'performance_index', 'reputation_score', 'executer_score', 'executer_per']\n",
    "BC = pd.DataFrame(columns = columns)\n",
    "\n",
    "reputation_cols = ['round', 'client_id', 'data_quality', 'resource_contribution', 'offloading_history', 'validation_score', 'performance_index', 'profit', 'data_quality_norm', 'resource_contribution_norm', 'validation_score_norm', 'reputation_score']\n",
    "REPUTATION_DATA = pd.DataFrame(columns = reputation_cols)\n",
    "\n",
    "# bid_cols = ['round', 'agent_id', 'auctioneer_id', 'bid', 'winner', 'bidder_reputation', 'auc_reputation', 'c_idx', 'payment', 'fair_payment']\n",
    "BID_POOL_LOCK = threading.Lock()\n",
    "bid_cols = ['round', 'agent_id', 'auctioneer_id', 'bid', 'winner', 'composed_reputation', 'c_idx', 'payment', 'fair_payment']\n",
    "BID_POOL = pd.DataFrame(columns = bid_cols)\n",
    "\n",
    "MODEL_POOL_LOCK = threading.Lock()\n",
    "model_pool_cols = ['round', 'level', 'owner', 'trainer', 'submodels_id', 'aggregators', 'aggregated', 'validators', 'validation_score', 'lock']\n",
    "\n",
    "MODEL_POOL = pd.DataFrame(columns = model_pool_cols, dtype='float32')\n",
    "\n",
    "## Total payment\n",
    "RHO_MIN = 0\n",
    "RHO_MAX = 10000\n",
    "\n",
    "## Shared variables\n",
    "NUM_CLIENTS = 50\n",
    "MODEL_WEIGHTS_SIZE = 0                          # The size of model weights size in bytes\n",
    "GLOBAL_MODEL_HOLDER = None\n",
    "DATA_UNIT_SIZE = 78400                          # The size of a single data unit (for example one image) in (Bytes)\n",
    "B_w = 15e3                                      # Bandwidth in (Hz)\n",
    "CAPACITANCE = 1e-28\n",
    "N_0 = -174                                      # Spectral density noise (dBm/Hz)\n",
    "TRANSMIT_POWER = 400                            # Transmission power in (mWatt)\n",
    "\n",
    "\n",
    "# State flags\n",
    "END_ROUND_LOCK = threading.Lock()\n",
    "END_ROUND = False\n",
    "END_TASK = False\n",
    "\n",
    "# Offloading variables\n",
    "OFFLOADING_TOKEN = threading.Lock()\n",
    "OFFLOADING_PROB = 0.1\n",
    "TOTAL_OFFLOADING = 0\n",
    "CURRENT_ROUND = 0\n",
    "\n",
    "AUCTION_OFFER_KEYS = ['timestamp', 'auction_ID', 'round', 'auctioneer_ID', 'offer']\n",
    "AUCTION_BID_KEYS = ['timestamp', 'auction_ID', 'bidder_ID', 'bid', 'true_action']\n",
    "AUCTION_REP_KEYS = ['timestamp', 'auction_ID', 'round', 'auctioneer_id', 'composed_reputation', 'bid', 'true_action', 'payment', 'task_args']\n",
    "\n",
    "## Federated Learning Parameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_ROUNDS = 50\n",
    "selected_clients = []\n",
    "\n",
    "## Reinfocement Learning Parameters\n",
    "DRL_BATCH_SIZE = 8              # Number of transitions sampled from replay memory\n",
    "DRL_DISCOUNT_FACTOR = 0.7       # Discount factor of Bellman equation\n",
    "DRL_EPS_START = 0.9             # Exploitation-exploration tradeoff factor\n",
    "DRL_EPS_END = 0.05\n",
    "DRL_EPS_DECAY = 1000            # Decay to control the decay of epsilon\n",
    "DRL_TAU = 0.005                 # Update rate of target network\n",
    "DRL_LEARNING_RATE = 1e-3        # Learning rate of DRL network\n",
    "BIDDER_UTILITY_THRESHOLD = 0.15\n",
    "STEPS_PER_EP = 8\n",
    "\n",
    "# Metrics\n",
    "METRICS_LOCK = threading.Lock()\n",
    "MEAN_REWARD = []\n",
    "BIDDER_UTILITY = []\n",
    "TOTAL_REPUTATION = []\n",
    "GLOBAL_ACCURACY = []\n",
    "ACTOR_LOSS = []\n",
    "CRITIC_LOSS = []\n",
    "TASK_DROP = []\n",
    "TASK_DROP_RATE = []\n",
    "\n",
    "\n",
    "# Linear regression model for future profit prediction\n",
    "LR_MODEL = LinearRegression()\n",
    "\n",
    "# Reinforcement Learning Environment\n",
    "ENV_LOCK = threading.Lock()\n",
    "env = gym.make(\"BiddingEnv-v0\", num_agents = NUM_CLIENTS)\n",
    "# env = NormalizedActions(env)\n",
    "\n",
    "# Set seed for random generators\n",
    "random.seed(42)\n",
    "# env.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# n_observations = env.get_n_observations()\n",
    "# action_range = env.get_action_range()\n",
    "n_observations = env.get_n_observations()\n",
    "n_actions = 1\n",
    "\n",
    "\n",
    "# hidden_size = (400, 300)\n",
    "hidden_size = (128, 64)\n",
    "\n",
    "# Create Replay Memory\n",
    "REPLAY_MEMORY = ReplayMemory(int(1e5))\n",
    "\n",
    "# Initialize OU-Noise\n",
    "nb_actions = env.action_space.shape[-1]\n",
    "ou_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(nb_actions), sigma=0.005 * np.ones(nb_actions))\n",
    "\n",
    "\n",
    "# Create DDPG Agent\n",
    "AGENT_LOCK = threading.Lock()\n",
    "DDPG_AGGREGATED = False\n",
    "DDPG_CHECK = False\n",
    "\n",
    "DDPG_AGENT = DDPG(\n",
    "              DRL_DISCOUNT_FACTOR,\n",
    "              DRL_TAU,\n",
    "              hidden_size,\n",
    "              n_observations,\n",
    "              env.action_space,\n",
    "              checkpoint_dir='./saved_models/BiddingEnv-v0'\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "# Prepare and split dataset\n",
    "trainloaders, valloaders, testloader=load_datasets(num_clients=NUM_CLIENTS*10, inter_iid=False, intra_iid=False)  #*100)\n",
    "network = Network(num_clients=NUM_CLIENTS, batch_size=BATCH_SIZE, testloader=testloader)\n",
    "\n",
    "# Read clients Details\n",
    "generate_clients(NUM_CLIENTS)\n",
    "client_df = pd.read_csv('client_data.csv')\n",
    "\n",
    "clients = [Client(\n",
    "    id=int(row['id']),\n",
    "    coordinates = (row['x_coordinate'], row['y_coordinate'], row['z_coordinate']),\n",
    "    trainloader=trainloaders[i],\n",
    "    valloader=valloaders[i],\n",
    "    epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    capacitance=CAPACITANCE,\n",
    "    cpu_cycles=row['cpu_cycles'],\n",
    "    power=TRANSMIT_POWER,\n",
    "    frequency=row['frequency']) for i, row in client_df.iterrows()]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "  executor.submit(network.launch_task, NUM_ROUNDS, LEARNING_RATE, NUM_EPOCHS)\n",
    "\n",
    "\n",
    "print(f'Total offloading events : {TOTAL_OFFLOADING}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eetTStFwAlF"
   },
   "source": [
    "References: \\\\\n",
    "transmission rate formula and simulation values:\n",
    "- https://ieeexplore.ieee.org/document/9521696/\n",
    "- https://ieeexplore.ieee.org/document/9372882\n",
    "- https://www.sciencedirect.com/science/article/pii/S0167739X23001383\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UG8qIrqD2Wf-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
